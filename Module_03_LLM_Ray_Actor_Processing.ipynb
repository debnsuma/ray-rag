{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53148ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers==3.4.1 in /home/ray/anaconda3/lib/python3.12/site-packages (3.4.1)\n",
      "Requirement already satisfied: chromadb==0.6.3 in /home/ray/anaconda3/lib/python3.12/site-packages (0.6.3)\n",
      "Requirement already satisfied: transformers==4.48.3 in /home/ray/anaconda3/lib/python3.12/site-packages (4.48.3)\n",
      "Requirement already satisfied: xgboost==2.1.4 in /home/ray/anaconda3/lib/python3.12/site-packages (2.1.4)\n",
      "Requirement already satisfied: tqdm in /home/ray/anaconda3/lib/python3.12/site-packages (from sentence-transformers==3.4.1) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/ray/anaconda3/lib/python3.12/site-packages (from sentence-transformers==3.4.1) (2.9.1)\n",
      "Requirement already satisfied: scikit-learn in /home/ray/anaconda3/lib/python3.12/site-packages (from sentence-transformers==3.4.1) (1.5.2)\n",
      "Requirement already satisfied: scipy in /home/ray/anaconda3/lib/python3.12/site-packages (from sentence-transformers==3.4.1) (1.11.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /home/ray/anaconda3/lib/python3.12/site-packages (from sentence-transformers==3.4.1) (0.36.0)\n",
      "Requirement already satisfied: Pillow in /home/ray/anaconda3/lib/python3.12/site-packages (from sentence-transformers==3.4.1) (10.4.0)\n",
      "Requirement already satisfied: build>=1.0.3 in /home/ray/anaconda3/lib/python3.12/site-packages (from chromadb==0.6.3) (1.3.0)\n",
      "Requirement already satisfied: pydantic>=1.9 in /home/ray/anaconda3/lib/python3.12/site-packages (from chromadb==0.6.3) (2.12.4)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in /home/ray/anaconda3/lib/python3.12/site-packages (from chromadb==0.6.3) (0.7.6)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /home/ray/anaconda3/lib/python3.12/site-packages (from chromadb==0.6.3) (0.121.0)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /home/ray/anaconda3/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.6.3) (0.22.0)\n",
      "Requirement already satisfied: numpy>=1.22.5 in /home/ray/anaconda3/lib/python3.12/site-packages (from chromadb==0.6.3) (1.26.4)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /home/ray/anaconda3/lib/python3.12/site-packages (from chromadb==0.6.3) (3.5.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /home/ray/anaconda3/lib/python3.12/site-packages (from chromadb==0.6.3) (4.15.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /home/ray/anaconda3/lib/python3.12/site-packages (from chromadb==0.6.3) (1.23.2)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /home/ray/anaconda3/lib/python3.12/site-packages (from chromadb==0.6.3) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /home/ray/anaconda3/lib/python3.12/site-packages (from chromadb==0.6.3) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /home/ray/anaconda3/lib/python3.12/site-packages (from chromadb==0.6.3) (0.60b1)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /home/ray/anaconda3/lib/python3.12/site-packages (from chromadb==0.6.3) (1.39.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /home/ray/anaconda3/lib/python3.12/site-packages (from chromadb==0.6.3) (0.21.4)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /home/ray/anaconda3/lib/python3.12/site-packages (from chromadb==0.6.3) (0.50.0)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /home/ray/anaconda3/lib/python3.12/site-packages (from chromadb==0.6.3) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /home/ray/anaconda3/lib/python3.12/site-packages (from chromadb==0.6.3) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /home/ray/anaconda3/lib/python3.12/site-packages (from chromadb==0.6.3) (1.74.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /home/ray/anaconda3/lib/python3.12/site-packages (from chromadb==0.6.3) (5.0.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in /home/ray/anaconda3/lib/python3.12/site-packages (from chromadb==0.6.3) (0.21.1)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /home/ray/anaconda3/lib/python3.12/site-packages (from chromadb==0.6.3) (35.0.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /home/ray/anaconda3/lib/python3.12/site-packages (from chromadb==0.6.3) (9.1.2)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in /home/ray/anaconda3/lib/python3.12/site-packages (from chromadb==0.6.3) (6.0.3)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /home/ray/anaconda3/lib/python3.12/site-packages (from chromadb==0.6.3) (5.2.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /home/ray/anaconda3/lib/python3.12/site-packages (from chromadb==0.6.3) (3.11.5)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /home/ray/anaconda3/lib/python3.12/site-packages (from chromadb==0.6.3) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/ray/anaconda3/lib/python3.12/site-packages (from chromadb==0.6.3) (13.7.1)\n",
      "Requirement already satisfied: filelock in /home/ray/anaconda3/lib/python3.12/site-packages (from transformers==4.48.3) (3.17.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ray/anaconda3/lib/python3.12/site-packages (from transformers==4.48.3) (24.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ray/anaconda3/lib/python3.12/site-packages (from transformers==4.48.3) (2026.1.15)\n",
      "Requirement already satisfied: requests in /home/ray/anaconda3/lib/python3.12/site-packages (from transformers==4.48.3) (2.32.5)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/ray/anaconda3/lib/python3.12/site-packages (from transformers==4.48.3) (0.7.0)\n",
      "Requirement already satisfied: nvidia-nccl-cu12 in /home/ray/anaconda3/lib/python3.12/site-packages (from xgboost==2.1.4) (2.27.5)\n",
      "Requirement already satisfied: pyproject_hooks in /home/ray/anaconda3/lib/python3.12/site-packages (from build>=1.0.3->chromadb==0.6.3) (1.2.0)\n",
      "Requirement already satisfied: starlette<0.50.0,>=0.40.0 in /home/ray/anaconda3/lib/python3.12/site-packages (from fastapi>=0.95.2->chromadb==0.6.3) (0.49.1)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in /home/ray/anaconda3/lib/python3.12/site-packages (from fastapi>=0.95.2->chromadb==0.6.3) (0.0.4)\n",
      "Requirement already satisfied: anyio in /home/ray/anaconda3/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb==0.6.3) (3.7.1)\n",
      "Requirement already satisfied: certifi in /home/ray/anaconda3/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb==0.6.3) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ray/anaconda3/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb==0.6.3) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/ray/anaconda3/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb==0.6.3) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in /home/ray/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb==0.6.3) (0.16.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ray/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers==3.4.1) (2023.12.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/ray/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers==3.4.1) (1.2.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/ray/anaconda3/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb==0.6.3) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /home/ray/anaconda3/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb==0.6.3) (2.8.2)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /home/ray/anaconda3/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb==0.6.3) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /home/ray/anaconda3/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb==0.6.3) (2.0.0)\n",
      "Requirement already satisfied: urllib3!=2.6.0,>=1.24.2 in /home/ray/anaconda3/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb==0.6.3) (1.26.19)\n",
      "Requirement already satisfied: durationpy>=0.7 in /home/ray/anaconda3/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb==0.6.3) (0.10)\n",
      "Requirement already satisfied: coloredlogs in /home/ray/anaconda3/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb==0.6.3) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /home/ray/anaconda3/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb==0.6.3) (25.12.19)\n",
      "Requirement already satisfied: protobuf in /home/ray/anaconda3/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb==0.6.3) (6.33.4)\n",
      "Requirement already satisfied: sympy in /home/ray/anaconda3/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb==0.6.3) (1.14.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /home/ray/anaconda3/lib/python3.12/site-packages (from opentelemetry-api>=1.2.0->chromadb==0.6.3) (6.11.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in /home/ray/anaconda3/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.6.3) (1.72.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.39.1 in /home/ray/anaconda3/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.6.3) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.39.1 in /home/ray/anaconda3/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.6.3) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.60b1 in /home/ray/anaconda3/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3) (0.60b1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.60b1 in /home/ray/anaconda3/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3) (0.60b1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.60b1 in /home/ray/anaconda3/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3) (0.60b1)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.60b1 in /home/ray/anaconda3/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3) (0.60b1)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /home/ray/anaconda3/lib/python3.12/site-packages (from opentelemetry-instrumentation==0.60b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3) (1.14.1)\n",
      "Requirement already satisfied: asgiref~=3.0 in /home/ray/anaconda3/lib/python3.12/site-packages (from opentelemetry-instrumentation-asgi==0.60b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3) (3.11.0)\n",
      "Requirement already satisfied: monotonic>=1.5 in /home/ray/anaconda3/lib/python3.12/site-packages (from posthog>=2.4.0->chromadb==0.6.3) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /home/ray/anaconda3/lib/python3.12/site-packages (from posthog>=2.4.0->chromadb==0.6.3) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ray/anaconda3/lib/python3.12/site-packages (from pydantic>=1.9->chromadb==0.6.3) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /home/ray/anaconda3/lib/python3.12/site-packages (from pydantic>=1.9->chromadb==0.6.3) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/ray/anaconda3/lib/python3.12/site-packages (from pydantic>=1.9->chromadb==0.6.3) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ray/anaconda3/lib/python3.12/site-packages (from requests->transformers==4.48.3) (3.3.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ray/anaconda3/lib/python3.12/site-packages (from rich>=10.11.0->chromadb==0.6.3) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ray/anaconda3/lib/python3.12/site-packages (from rich>=10.11.0->chromadb==0.6.3) (2.18.0)\n",
      "Requirement already satisfied: setuptools in /home/ray/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers==3.4.1) (75.8.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/ray/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers==3.4.1) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /home/ray/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers==3.4.1) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/ray/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers==3.4.1) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/ray/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers==3.4.1) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/ray/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers==3.4.1) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/ray/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers==3.4.1) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/ray/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers==3.4.1) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/ray/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers==3.4.1) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/ray/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers==3.4.1) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/ray/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers==3.4.1) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/ray/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers==3.4.1) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/ray/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers==3.4.1) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /home/ray/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers==3.4.1) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/ray/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers==3.4.1) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/ray/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers==3.4.1) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/ray/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers==3.4.1) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in /home/ray/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers==3.4.1) (3.5.1)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/ray/anaconda3/lib/python3.12/site-packages (from typer>=0.9.0->chromadb==0.6.3) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/ray/anaconda3/lib/python3.12/site-packages (from typer>=0.9.0->chromadb==0.6.3) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /home/ray/anaconda3/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.6.3) (0.7.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /home/ray/anaconda3/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.6.3) (1.2.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /home/ray/anaconda3/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.6.3) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /home/ray/anaconda3/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.6.3) (0.19.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /home/ray/anaconda3/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.6.3) (11.0.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/ray/anaconda3/lib/python3.12/site-packages (from scikit-learn->sentence-transformers==3.4.1) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/ray/anaconda3/lib/python3.12/site-packages (from scikit-learn->sentence-transformers==3.4.1) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ray/anaconda3/lib/python3.12/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb==0.6.3) (3.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ray/anaconda3/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb==0.6.3) (0.1.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ray/anaconda3/lib/python3.12/site-packages (from anyio->httpx>=0.27.0->chromadb==0.6.3) (1.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ray/anaconda3/lib/python3.12/site-packages (from sympy->onnxruntime>=1.14.1->chromadb==0.6.3) (1.3.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/ray/anaconda3/lib/python3.12/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.6.3) (10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ray/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers==3.4.1) (2.1.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ray/anaconda3/lib/python3.12/site-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb==0.6.3) (3.2.2)\n",
      "\n",
      "\u001b[93m#################\n",
      "\n",
      "ANYSCALE WARNING:\n",
      "Arguments ['--no-cache-dir'] might not be applied correctly across cluster, please check our documentation for supported flags: https://docs.anyscale.com/configuration/dependency-management/dependency-development\n",
      "\n",
      "#################\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[92mSuccessfully registered `sentence-transformers, chromadb` and 2 other packages to be installed on all cluster nodes.\u001b[0m\n",
      "\u001b[92mView and update dependencies here: https://console.anyscale.com/cld_g54aiirwj1s8t9ktgzikqur41k/prj_f1j47h9srml4cyg962id75ms2e/workspaces/expwrk_llznag1z2l695idvwp9pkhy1sj?workspace-tab=dependencies\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --no-cache-dir --upgrade \"sentence-transformers==3.4.1\" \"chromadb==0.6.3\" \"transformers==4.48.3\" \"xgboost==2.1.4\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eee788c7-5783-4162-b1c8-00fe2a30de76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392f9ef9-7f9e-446d-8876-40ca04f40b38",
   "metadata": {},
   "source": [
    "# Running a LLM with Ray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63008356-89cd-41e3-b9f4-003f228d739b",
   "metadata": {},
   "source": [
    "__Road Map__:\n",
    "* Ray Core + Huggingface\n",
    "* Motivating Actors\n",
    "* Ray Core Actor\n",
    "* Using Actors in Ray AI Libraries\n",
    "* Ray Data\n",
    "* Ray Serve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c5aaee4-e3cd-4119-aad3-74a9768549d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import ray\n",
    "\n",
    "CHAT_MODEL = 'Qwen/Qwen2.5-0.5B-Instruct'\n",
    "\n",
    "prompt = \"Tell me something about large language models.\"\n",
    "\n",
    "@ray.remote(num_gpus=1) \n",
    "# Ray accounts for resources for schedule/load purposes and sets CUDA_VISIBLE_DEVICES but does not enforce resource usage quotas\n",
    "def basic_hf(prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    pipe = pipeline(\"text-generation\", model=CHAT_MODEL, device='cuda', model_kwargs={\"cache_dir\": \"/mnt/local_storage\"})\n",
    "    return pipe(messages, max_new_tokens=200, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37467332-4761-4b55-9aba-e0cd9235e22e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-20 21:23:13,248\tINFO worker.py:1821 -- Connecting to existing Ray cluster at address: 10.0.142.230:6379...\n",
      "2026-01-20 21:23:13,263\tINFO worker.py:1998 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32mhttps://session-v4klp1kjtnk9yrxwdcz5ah11ub.i.anyscaleuserdata.com \u001b[39m\u001b[22m\n",
      "2026-01-20 21:23:13,303\tINFO packaging.py:463 -- Pushing file package 'gcs://_ray_pkg_0bd8078b0063d4195929ce96a7cf436461a67169.zip' (9.62MiB) to Ray cluster...\n",
      "2026-01-20 21:23:13,348\tINFO packaging.py:476 -- Successfully pushed file package 'gcs://_ray_pkg_0bd8078b0063d4195929ce96a7cf436461a67169.zip'.\n",
      "/home/ray/anaconda3/lib/python3.12/site-packages/ray/_private/worker.py:2046: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ref = basic_hf.remote(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c5ab5fa-0bc2-453c-9f67-dde3bb774296",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(basic_hf pid=38379, ip=10.0.177.60)\u001b[0m Device set to use cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': [{'role': 'system',\n",
       "    'content': 'You are a helpful assistant.'},\n",
       "   {'role': 'user',\n",
       "    'content': 'Tell me something about large language models.'},\n",
       "   {'role': 'assistant',\n",
       "    'content': \"Large language models (LLMs) are artificial intelligence programs that can produce human-like text based on the input they receive. These LLMs are often used for tasks such as translation, summarization, and question-answering.\\n\\nOne of the key features of LLMs is their ability to generate vast amounts of text quickly and efficiently. They use techniques such as neural networks and transformers to understand the meaning of words and phrases and generate natural-sounding responses.\\n\\nLLMs have been used in a wide range of applications, including customer service, healthcare, legal research, and more. For example, companies like Google and IBM have developed LLMs that can assist with customer support by generating responses to common questions.\\n\\nHowever, it's important to note that the accuracy and reliability of LLMs can be affected by factors such as the quality and diversity of training data, the complexity of the input, and the size of the model itself. Additionally, there is ongoing debate about whether LLMs should\"}]}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.get(ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e3c077-8721-47e8-b149-c82ab4a9ad87",
   "metadata": {
    "tags": []
   },
   "source": [
    "What's wrong with this code? We're loading the model from storage on every call.\n",
    "\n",
    "What's the solution? Ray Actors!\n",
    "\n",
    "Define an actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2b73177-cc78-4f10-995b-f7bdc91d65e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@ray.remote(num_gpus=0.15)\n",
    "class Chat:\n",
    "    def __init__(self, model: str):\n",
    "        self.pipe = pipeline(\"text-generation\", model=model, device='cuda', model_kwargs={\"cache_dir\": \"/mnt/local_storage\"})\n",
    "\n",
    "    def reply(self, prompts):\n",
    "        messages = [ [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ] for prompt in prompts]\n",
    "        return self.pipe(messages, max_new_tokens=200, truncation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdad79b-6f13-42ae-82ae-831654ddbdd5",
   "metadata": {},
   "source": [
    "Instantiate one or more actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ba72ce7-604a-4a2c-9c07-d3de0e16a68a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat = Chat.remote(CHAT_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d556cbdb-a986-4b4d-90c8-d068a9ab6c92",
   "metadata": {},
   "source": [
    "Make multiple calls to the same actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04d1251d-6684-4be1-a028-cc3130668f9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(Chat pid=40427, ip=10.0.162.181)\u001b[0m Device set to use cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'generated_text': [{'role': 'system',\n",
       "     'content': 'You are a helpful assistant.'},\n",
       "    {'role': 'user', 'content': 'What are some top attractions in Seattle?'},\n",
       "    {'role': 'assistant',\n",
       "     'content': 'Seattle is a city with many beautiful and historic attractions, including:\\n\\n1. The Microsoft Building - a former computer company building that has been converted into a museum.\\n\\n2. The Kingdome - home to the Seattle Mariners baseball team.\\n\\n3. The Seattle Aquarium - a marine life center located on the waterfront.\\n\\n4. The Space Needle - an iconic suspension bridge that offers stunning views of the city.\\n\\n5. The Pike Place Market - a bustling market filled with local shops, food vendors, and live music.\\n\\n6. The University of Washington - a world-renowned university with a rich history dating back to 1870.\\n\\n7. The University of Washington Stadium - the home field for the Seattle Seahawks football team.\\n\\n8. The Boeing Company Museum - a historical museum dedicated to the aviation industry.\\n\\n9. The University of Washington Center for the Arts - features galleries, studios, and performance spaces.\\n\\n10. The University of Washington Press - a bookstore and literary institution.\\n\\nThese are just a'}]}],\n",
       " [{'generated_text': [{'role': 'system',\n",
       "     'content': 'You are a helpful assistant.'},\n",
       "    {'role': 'user',\n",
       "     'content': 'What are some top attractions in Los Angeles?'},\n",
       "    {'role': 'assistant',\n",
       "     'content': '1. Getty Museum: A museum dedicated to the history and art of the Western world, featuring works by artists from all over the globe.\\n\\n2. The Getty Center: A historic building that houses the Getty Museum and other galleries and museums.\\n\\n3. Universal Studios Hollywood: One of the most famous theme parks in the world, offering rides like the Ferris wheel, bumper cars, and roller coasters.\\n\\n4. Disneyland Paris: Another popular theme park with attractions such as the Eiffel Tower, the Haunted House, and the Star Wars Galaxy.\\n\\n5. The Walt Disney World Resort: Home to many attractions including the Epcot center, Mardi Gras Square, and Magic Kingdom.\\n\\n6. Griffith Observatory: An observatory located on the edge of Griffith Park that offers stunning views of the city.\\n\\n7. La Brea Tar Pits: Located just outside of Los Angeles, this natural formation is believed to be thousands of years old and contains fossils of prehistoric animals.\\n\\n8.'}]}]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = [\"What are some top attractions in Seattle?\", \"What are some top attractions in Los Angeles?\"]\n",
    "\n",
    "ref = chat.reply.remote(queries) \n",
    "\n",
    "ray.get(ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e8b8b36-b70e-42cc-88e9-ea87a438eafe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'generated_text': [{'role': 'system',\n",
       "     'content': 'You are a helpful assistant.'},\n",
       "    {'role': 'user',\n",
       "     'content': 'What are some top attractions in Vancouver BC?'},\n",
       "    {'role': 'assistant',\n",
       "     'content': \"Vancouver, British Columbia is one of Canada's most popular tourist destinations and home to many amazing attractions. Here are some of the top ones:\\n\\n1. Stanley Park - A stunning park with beautiful lakeside views and numerous hiking trails.\\n\\n2. The Vancouver Art Gallery - One of the largest art museums in North America, it houses an impressive collection of Canadian and international works.\\n\\n3. The Vancouver Aquarium - Home to over 400 marine animals from around the world, including sea turtles, sharks, and dolphins.\\n\\n4. Granville Island - A small island off the coast of Vancouver that offers stunning views of the city and the ocean.\\n\\n5. Mount St. Elias - A mountain range located on Vancouver Island, offering breathtaking views and hiking opportunities.\\n\\n6. The Vantage Point - A panoramic viewing platform overlooking the entire city of Vancouver, providing incredible views of the city skyline and surrounding landscapes.\\n\\n7. The Olympic Park - An open-air museum dedicated to showcasing the history and culture of Vancouver during\"}]}],\n",
       " [{'generated_text': [{'role': 'system',\n",
       "     'content': 'You are a helpful assistant.'},\n",
       "    {'role': 'user',\n",
       "     'content': 'What are some top attractions in Portland OR?'},\n",
       "    {'role': 'assistant',\n",
       "     'content': \"Portland, Oregon is known for its diverse array of attractions and experiences, including:\\n\\n1. The Oregon Trail National Historical Park - This park features the historic Oregon Trail, where early settlers set out to start a new life in America.\\n\\n2. The Oregon Museum of Science and Industry (OMSI) - Located in Beaverton, this museum showcases science and technology, with exhibits on topics ranging from astronomy and physics to engineering and robotics.\\n\\n3. The Portland Museum of Art - A major art museum that houses over 40,000 works of art, from ancient Egyptian artifacts to contemporary installations.\\n\\n4. The Willamette River Walk - Take a stroll along the Willamette River in downtown Portland, which offers stunning views of the river and surrounding landscapes.\\n\\n5. The Oregon State Capitol Building - Home to the state's legislative body, the Oregon State Capitol building is a modern, glass-enclosed structure that offers visitors a unique vantage point of the city.\\n\\n6. The University\"}]}]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "more_queries = [\"What are some top attractions in Vancouver BC?\", \"What are some top attractions in Portland OR?\"]\n",
    "\n",
    "ray.get(chat.reply.remote(more_queries))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7132de9b-ab5c-417d-8976-304c00444c27",
   "metadata": {},
   "source": [
    "## Ray Data + Actors: LLM Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d99e63ec-03a3-491c-9214-e1b87bcfe9af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cp prompts.parquet /mnt/cluster_storage/prompts.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e3c8deb-288a-4881-89e3-c153793f43e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompts = ray.data.read_parquet('/mnt/cluster_storage/prompts.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bda641d7-f001-4072-83ea-9c66dcad3bc9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-20 21:25:17,147\tINFO logging.py:397 -- Registered dataset logger for dataset dataset_209_0\n",
      "2026-01-20 21:25:17,170\tINFO streaming_executor.py:178 -- Starting execution of Dataset dataset_209_0. Full logs are in /tmp/ray/session_2026-01-20_18-18-31_241199_2386/logs/ray-data\n",
      "2026-01-20 21:25:17,171\tINFO streaming_executor.py:179 -- Execution plan of Dataset dataset_209_0: InputDataBuffer[Input] -> TaskPoolMapOperator[ListFiles] -> TaskPoolMapOperator[ReadFiles] -> LimitOperator[limit=5]\n",
      "2026-01-20 21:25:17,172\tINFO streaming_executor.py:687 -- [dataset]: A new progress UI is available. To enable, set `ray.data.DataContext.get_current().enable_rich_progress_bars = True` and `ray.data.DataContext.get_current().use_ray_tqdm = False`.\n",
      "2026-01-20 21:25:17,173\tINFO progress_bar.py:155 -- Progress bar disabled because stdout is a non-interactive terminal.\n",
      "2026-01-20 21:25:17,174\tWARNING resource_manager.py:136 -- ⚠️  Ray's object store is configured to use only 27.8% of available memory (40.0GiB out of 144.0GiB total). For optimal Ray Data performance, we recommend setting the object store to at least 50% of available memory. You can do this by setting the 'object_store_memory' parameter when calling ray.init() or by setting the RAY_DEFAULT_OBJECT_STORE_MEMORY_PROPORTION environment variable.\n",
      "2026-01-20 21:25:17,200\tINFO progress_bar.py:213 -- === Ray Data Progress {ListFiles} ===\n",
      "2026-01-20 21:25:17,200\tINFO progress_bar.py:215 -- ListFiles: Tasks: 1; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 384.0MiB object store: Progress Completed 0 / ?\n",
      "2026-01-20 21:25:17,201\tINFO progress_bar.py:213 -- === Ray Data Progress {ReadFiles} ===\n",
      "2026-01-20 21:25:17,202\tINFO progress_bar.py:215 -- ReadFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
      "2026-01-20 21:25:17,203\tINFO progress_bar.py:213 -- === Ray Data Progress {limit=5} ===\n",
      "2026-01-20 21:25:17,204\tINFO progress_bar.py:215 -- limit=5: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
      "2026-01-20 21:25:17,205\tINFO progress_bar.py:213 -- === Ray Data Progress {Running Dataset} ===\n",
      "2026-01-20 21:25:17,205\tINFO progress_bar.py:215 -- Running Dataset: dataset_209_0. Active & requested resources: 0/32 CPU, 0.0B/26.9GiB object store: Progress Completed 0 / ?\n",
      "2026-01-20 21:25:22,208\tINFO progress_bar.py:215 -- ListFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 61.0B object store: Progress Completed 1 / 1\n",
      "2026-01-20 21:25:22,208\tINFO progress_bar.py:215 -- ReadFiles: Tasks: 1; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 384.0MiB object store: Progress Completed 0 / ?\n",
      "2026-01-20 21:25:22,209\tINFO progress_bar.py:215 -- limit=5: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
      "2026-01-20 21:25:22,210\tINFO progress_bar.py:215 -- Running Dataset: dataset_209_0. Active & requested resources: 1/32 CPU, 384.0MiB/26.9GiB object store: Progress Completed 0 / ?\n",
      "2026-01-20 21:25:27,343\tINFO progress_bar.py:215 -- ListFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 61.0B object store: Progress Completed 1 / 1\n",
      "2026-01-20 21:25:27,344\tINFO progress_bar.py:215 -- ReadFiles: Tasks: 1; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 3.0KiB object store: Progress Completed 23 / ?\n",
      "2026-01-20 21:25:27,345\tINFO progress_bar.py:215 -- limit=5: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 244.0B object store: Progress Completed 0 / ?\n",
      "2026-01-20 21:25:27,346\tINFO progress_bar.py:215 -- Running Dataset: dataset_209_0. Active & requested resources: 1/32 CPU, 4.6KiB/26.9GiB object store: Progress Completed 0 / ?\n",
      "2026-01-20 21:25:27,360\tINFO streaming_executor.py:305 -- ✔️  Dataset dataset_209_0 execution finished in 10.19 seconds\n",
      "INFO:openlineage.client.client:OpenLineageClient will use `composite` transport\n",
      "INFO:openlineage.client.transport.composite:Stopping OpenLineage CompositeTransport emission after the first successful delivery because `continue_on_success=False`. Transport that emitted the event: <HttpTransport(name=first, kind=http, priority=1)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'prompt': array(['Describe the body of water in Utah?',\n",
       "        'Tell as much as you can about the robbery?',\n",
       "        'Did Phileas Fogg really rob the bank?',\n",
       "        'Who is the main protagonist of Around the World in 80 Days?',\n",
       "        'What is the name of Phileas Fogg’s loyal servant?'], dtype=object)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts.limit(5).take_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dded6a5-66e4-444e-bbef-2e6b2e1351f1",
   "metadata": {},
   "source": [
    "Recall that the workhorse of Ray Data processing pipelines is the `map_batches` API call on a `Dataset`\n",
    "\n",
    "`map_batches` supports stateless (tasks) and statefull (actors) processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ef39584-7d90-45b6-b6a8-8270ed7db9cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PromptEnhancer:\n",
    "    def __call__(self, batch):\n",
    "        inputs = batch['prompt']\n",
    "        outputs = [ [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt }\n",
    "        ] for prompt in inputs]\n",
    "        batch['enhanced_prompt'] = outputs\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e81a933-cfd1-4eb3-a1c7-b42ec9853c93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-20 21:25:27,591\tWARNING util.py:599 -- The argument ``concurrency`` is deprecated in Ray 2.51. Please specify argument ``compute`` instead. For more information, see https://docs.ray.io/en/master/data/transforming-data.html#stateful-transforms.\n",
      "2026-01-20 21:25:27,594\tINFO logging.py:397 -- Registered dataset logger for dataset dataset_212_0\n",
      "2026-01-20 21:25:27,600\tINFO streaming_executor.py:178 -- Starting execution of Dataset dataset_212_0. Full logs are in /tmp/ray/session_2026-01-20_18-18-31_241199_2386/logs/ray-data\n",
      "2026-01-20 21:25:27,600\tINFO streaming_executor.py:179 -- Execution plan of Dataset dataset_212_0: InputDataBuffer[Input] -> TaskPoolMapOperator[ListFiles] -> TaskPoolMapOperator[ReadFiles] -> LimitOperator[limit=5] -> ActorPoolMapOperator[MapBatches(PromptEnhancer)]\n",
      "2026-01-20 21:25:27,775\tINFO progress_bar.py:213 -- === Ray Data Progress {ListFiles} ===\n",
      "2026-01-20 21:25:27,776\tINFO progress_bar.py:215 -- ListFiles: Tasks: 1; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 384.0MiB object store: Progress Completed 0 / ?\n",
      "2026-01-20 21:25:27,777\tINFO progress_bar.py:213 -- === Ray Data Progress {ReadFiles} ===\n",
      "2026-01-20 21:25:27,778\tINFO progress_bar.py:215 -- ReadFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
      "2026-01-20 21:25:27,779\tINFO progress_bar.py:213 -- === Ray Data Progress {limit=5} ===\n",
      "2026-01-20 21:25:27,779\tINFO progress_bar.py:215 -- limit=5: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
      "2026-01-20 21:25:27,780\tINFO progress_bar.py:213 -- === Ray Data Progress {MapBatches(PromptEnhancer)} ===\n",
      "2026-01-20 21:25:27,781\tINFO progress_bar.py:215 -- MapBatches(PromptEnhancer): Tasks: 0; Actors: 2 (running=0, restarting=0, pending=2); Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store; [all objects local]: Progress Completed 0 / ?\n",
      "2026-01-20 21:25:27,782\tINFO progress_bar.py:213 -- === Ray Data Progress {Running Dataset} ===\n",
      "2026-01-20 21:25:27,783\tINFO progress_bar.py:215 -- Running Dataset: dataset_212_0. Active & requested resources: 0/32 CPU, 0.0B/26.9GiB object store (pending: 2 CPU): Progress Completed 0 / ?\n",
      "/home/ray/anaconda3/lib/python3.12/site-packages/ray/data/_internal/execution/operators/actor_pool_map_operator.py:416: UserWarning: The minimum number of concurrent actors for 'MapBatches(PromptEnhancer)' is set to 2, but the operator only received 1 input(s). This means that the operator can launch at most 1 task(s), and won't fully utilize the available concurrency. You might be able to increase the number of concurrent tasks by configuring `override_num_blocks` earlier in the pipeline.\n",
      "  warnings.warn(\n",
      "2026-01-20 21:25:30,833\tINFO streaming_executor.py:305 -- ✔️  Dataset dataset_212_0 execution finished in 3.23 seconds\n",
      "INFO:openlineage.client.transport.composite:Stopping OpenLineage CompositeTransport emission after the first successful delivery because `continue_on_success=False`. Transport that emitted the event: <HttpTransport(name=first, kind=http, priority=1)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'prompt': array(['Describe the body of water in Utah?',\n",
       "        'Tell as much as you can about the robbery?',\n",
       "        'Did Phileas Fogg really rob the bank?',\n",
       "        'Who is the main protagonist of Around the World in 80 Days?',\n",
       "        'What is the name of Phileas Fogg’s loyal servant?'], dtype=object),\n",
       " 'enhanced_prompt': array([array([{'content': 'You are a helpful assistant.', 'role': 'system'},\n",
       "               {'content': 'Describe the body of water in Utah?', 'role': 'user'}],\n",
       "              dtype=object)                                                        ,\n",
       "        array([{'content': 'You are a helpful assistant.', 'role': 'system'},\n",
       "               {'content': 'Tell as much as you can about the robbery?', 'role': 'user'}],\n",
       "              dtype=object)                                                               ,\n",
       "        array([{'content': 'You are a helpful assistant.', 'role': 'system'},\n",
       "               {'content': 'Did Phileas Fogg really rob the bank?', 'role': 'user'}],\n",
       "              dtype=object)                                                          ,\n",
       "        array([{'content': 'You are a helpful assistant.', 'role': 'system'},\n",
       "               {'content': 'Who is the main protagonist of Around the World in 80 Days?', 'role': 'user'}],\n",
       "              dtype=object)                                                                                ,\n",
       "        array([{'content': 'You are a helpful assistant.', 'role': 'system'},\n",
       "               {'content': 'What is the name of Phileas Fogg’s loyal servant?', 'role': 'user'}],\n",
       "              dtype=object)                                                                      ],\n",
       "       dtype=object)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts.limit(5).map_batches(PromptEnhancer, concurrency=2).take_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd684f64-e0c9-49a8-b78a-be093bdbded9",
   "metadata": {},
   "source": [
    "Similar result, different internal semantics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0876bdff-8baa-41bc-9fd5-3a156dcaaf3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-20 21:25:30,927\tWARNING util.py:599 -- The argument ``concurrency`` is deprecated in Ray 2.51. Please specify argument ``compute`` instead. For more information, see https://docs.ray.io/en/master/data/transforming-data.html#stateful-transforms.\n",
      "2026-01-20 21:25:30,932\tINFO logging.py:397 -- Registered dataset logger for dataset dataset_214_0\n",
      "2026-01-20 21:25:30,936\tINFO streaming_executor.py:178 -- Starting execution of Dataset dataset_214_0. Full logs are in /tmp/ray/session_2026-01-20_18-18-31_241199_2386/logs/ray-data\n",
      "2026-01-20 21:25:30,936\tINFO streaming_executor.py:179 -- Execution plan of Dataset dataset_214_0: InputDataBuffer[Input] -> TaskPoolMapOperator[ListFiles] -> TaskPoolMapOperator[ReadFiles] -> LimitOperator[limit=5] -> ActorPoolMapOperator[MapBatches(PromptEnhancer)]\n",
      "2026-01-20 21:25:31,095\tINFO progress_bar.py:213 -- === Ray Data Progress {ListFiles} ===\n",
      "2026-01-20 21:25:31,096\tINFO progress_bar.py:215 -- ListFiles: Tasks: 1; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 384.0MiB object store: Progress Completed 0 / ?\n",
      "2026-01-20 21:25:31,097\tINFO progress_bar.py:213 -- === Ray Data Progress {ReadFiles} ===\n",
      "2026-01-20 21:25:31,098\tINFO progress_bar.py:215 -- ReadFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
      "2026-01-20 21:25:31,099\tINFO progress_bar.py:213 -- === Ray Data Progress {limit=5} ===\n",
      "2026-01-20 21:25:31,100\tINFO progress_bar.py:215 -- limit=5: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
      "2026-01-20 21:25:31,101\tINFO progress_bar.py:213 -- === Ray Data Progress {MapBatches(PromptEnhancer)} ===\n",
      "2026-01-20 21:25:31,101\tINFO progress_bar.py:215 -- MapBatches(PromptEnhancer): Tasks: 0; Actors: 2 (running=0, restarting=0, pending=2); Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store; [all objects local]: Progress Completed 0 / ?\n",
      "2026-01-20 21:25:31,102\tINFO progress_bar.py:213 -- === Ray Data Progress {Running Dataset} ===\n",
      "2026-01-20 21:25:31,103\tINFO progress_bar.py:215 -- Running Dataset: dataset_214_0. Active & requested resources: 0/32 CPU, 0.0B/26.9GiB object store (pending: 2 CPU): Progress Completed 0 / ?\n",
      "2026-01-20 21:25:35,072\tINFO streaming_executor.py:305 -- ✔️  Dataset dataset_214_0 execution finished in 4.13 seconds\n",
      "INFO:openlineage.client.transport.composite:Stopping OpenLineage CompositeTransport emission after the first successful delivery because `continue_on_success=False`. Transport that emitted the event: <HttpTransport(name=first, kind=http, priority=1)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'prompt': array(['Describe the body of water in Utah?',\n",
       "        'Tell as much as you can about the robbery?',\n",
       "        'Did Phileas Fogg really rob the bank?',\n",
       "        'Who is the main protagonist of Around the World in 80 Days?',\n",
       "        'What is the name of Phileas Fogg’s loyal servant?'], dtype=object),\n",
       " 'enhanced_prompt': array([array([{'content': 'You are a helpful assistant.', 'role': 'system'},\n",
       "               {'content': 'Describe the body of water in Utah?', 'role': 'user'}],\n",
       "              dtype=object)                                                        ,\n",
       "        array([{'content': 'You are a helpful assistant.', 'role': 'system'},\n",
       "               {'content': 'Tell as much as you can about the robbery?', 'role': 'user'}],\n",
       "              dtype=object)                                                               ,\n",
       "        array([{'content': 'You are a helpful assistant.', 'role': 'system'},\n",
       "               {'content': 'Did Phileas Fogg really rob the bank?', 'role': 'user'}],\n",
       "              dtype=object)                                                          ,\n",
       "        array([{'content': 'You are a helpful assistant.', 'role': 'system'},\n",
       "               {'content': 'Who is the main protagonist of Around the World in 80 Days?', 'role': 'user'}],\n",
       "              dtype=object)                                                                                ,\n",
       "        array([{'content': 'You are a helpful assistant.', 'role': 'system'},\n",
       "               {'content': 'What is the name of Phileas Fogg’s loyal servant?', 'role': 'user'}],\n",
       "              dtype=object)                                                                      ],\n",
       "       dtype=object)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts.map_batches(PromptEnhancer, concurrency=2).take_batch(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8e1b4e-8ef4-48cb-903b-fdbcfdb19ccf",
   "metadata": {},
   "source": [
    "Once we have prompts, we can extend the pipeline with our LLM Chat functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "181ddbc8-c2de-4bfa-a509-a90dd77a2a35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Chat:\n",
    "    def __init__(self, model: str):\n",
    "        self.pipe = pipeline(\"text-generation\", model=model, device='cuda', model_kwargs={\"cache_dir\": \"/mnt/local_storage\"})\n",
    "    \n",
    "    def __call__(self, batch):\n",
    "        enhanced_prompts = [[j for j in i] for i in batch['enhanced_prompt']]\n",
    "        batch['responses'] = self.pipe(enhanced_prompts, max_new_tokens=200, truncation=True)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfcbbc6-261e-4e21-b789-955e45b48c29",
   "metadata": {},
   "source": [
    "Note that in this usage, we specify the resources in the `map_batches` call rather than on the actor (class) definition itself.\n",
    "\n",
    "As we'll see later, this provides more flexibility for performance and scaling purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a86b7305-79d6-414c-937e-ccba8fe379e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-20 21:25:35,492\tWARNING util.py:599 -- The argument ``concurrency`` is deprecated in Ray 2.51. Please specify argument ``compute`` instead. For more information, see https://docs.ray.io/en/master/data/transforming-data.html#stateful-transforms.\n",
      "2026-01-20 21:25:35,494\tWARNING util.py:599 -- The argument ``concurrency`` is deprecated in Ray 2.51. Please specify argument ``compute`` instead. For more information, see https://docs.ray.io/en/master/data/transforming-data.html#stateful-transforms.\n",
      "2026-01-20 21:25:35,497\tINFO logging.py:397 -- Registered dataset logger for dataset dataset_218_0\n",
      "2026-01-20 21:25:35,503\tINFO streaming_executor.py:178 -- Starting execution of Dataset dataset_218_0. Full logs are in /tmp/ray/session_2026-01-20_18-18-31_241199_2386/logs/ray-data\n",
      "2026-01-20 21:25:35,503\tINFO streaming_executor.py:179 -- Execution plan of Dataset dataset_218_0: InputDataBuffer[Input] -> TaskPoolMapOperator[ListFiles] -> TaskPoolMapOperator[ReadFiles] -> LimitOperator[limit=5] -> ActorPoolMapOperator[MapBatches(PromptEnhancer)] -> ActorPoolMapOperator[MapBatches(Chat)]\n",
      "2026-01-20 21:25:35,707\tINFO progress_bar.py:213 -- === Ray Data Progress {ListFiles} ===\n",
      "2026-01-20 21:25:35,708\tINFO progress_bar.py:215 -- ListFiles: Tasks: 1; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 384.0MiB object store: Progress Completed 0 / ?\n",
      "2026-01-20 21:25:35,708\tINFO progress_bar.py:213 -- === Ray Data Progress {ReadFiles} ===\n",
      "2026-01-20 21:25:35,710\tINFO progress_bar.py:215 -- ReadFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
      "2026-01-20 21:25:35,711\tINFO progress_bar.py:213 -- === Ray Data Progress {limit=5} ===\n",
      "2026-01-20 21:25:35,712\tINFO progress_bar.py:215 -- limit=5: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
      "2026-01-20 21:25:35,712\tINFO progress_bar.py:213 -- === Ray Data Progress {MapBatches(PromptEnhancer)} ===\n",
      "2026-01-20 21:25:35,713\tINFO progress_bar.py:215 -- MapBatches(PromptEnhancer): Tasks: 0; Actors: 2 (running=0, restarting=0, pending=2); Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store; [all objects local]: Progress Completed 0 / ?\n",
      "2026-01-20 21:25:35,714\tINFO progress_bar.py:213 -- === Ray Data Progress {MapBatches(Chat)} ===\n",
      "2026-01-20 21:25:35,715\tINFO progress_bar.py:215 -- MapBatches(Chat): Tasks: 0; Actors: 2 (running=0, restarting=0, pending=2); Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store; [all objects local]: Progress Completed 0 / ?\n",
      "2026-01-20 21:25:35,716\tINFO progress_bar.py:213 -- === Ray Data Progress {Running Dataset} ===\n",
      "2026-01-20 21:25:35,716\tINFO progress_bar.py:215 -- Running Dataset: dataset_218_0. Active & requested resources: 0/32 CPU, 0.0B/26.9GiB object store (pending: 2 CPU, 0.3 GPU): Progress Completed 0 / ?\n",
      "2026-01-20 21:25:40,745\tINFO progress_bar.py:215 -- ListFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 1 / 1\n",
      "2026-01-20 21:25:40,745\tINFO progress_bar.py:215 -- ReadFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 23 / 23\n",
      "2026-01-20 21:25:40,746\tINFO progress_bar.py:215 -- limit=5: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 5 / 5\n",
      "2026-01-20 21:25:40,747\tINFO progress_bar.py:215 -- MapBatches(PromptEnhancer): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 758.0B object store; [0/1 objects local]: Progress Completed 5 / 5\n",
      "2026-01-20 21:25:40,747\tINFO progress_bar.py:215 -- MapBatches(Chat): Tasks: 0; Actors: 2 (running=0, restarting=0, pending=2); Queued blocks: 1 (758.0B); Resources: 0.0 CPU, 0.0B object store; [all objects local]: Progress Completed 0 / ?\n",
      "2026-01-20 21:25:40,748\tINFO progress_bar.py:215 -- Running Dataset: dataset_218_0. Active & requested resources: 0/32 CPU, 758.0B/26.9GiB object store (pending: 0.3 GPU): Progress Completed 0 / ?\n",
      "\u001b[36m(MapWorker(MapBatches(Chat)) pid=40804, ip=10.0.162.181)\u001b[0m Device set to use cuda\n",
      "/home/ray/anaconda3/lib/python3.12/site-packages/ray/data/_internal/execution/operators/actor_pool_map_operator.py:416: UserWarning: The minimum number of concurrent actors for 'MapBatches(Chat)' is set to 2, but the operator only received 1 input(s). This means that the operator can launch at most 1 task(s), and won't fully utilize the available concurrency. You might be able to increase the number of concurrent tasks by configuring `override_num_blocks` earlier in the pipeline.\n",
      "  warnings.warn(\n",
      "2026-01-20 21:25:45,749\tINFO progress_bar.py:215 -- ListFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 1 / 1\n",
      "2026-01-20 21:25:45,750\tINFO progress_bar.py:215 -- ReadFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 23 / 23\n",
      "2026-01-20 21:25:45,751\tINFO progress_bar.py:215 -- limit=5: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 5 / 5\n",
      "2026-01-20 21:25:45,752\tINFO progress_bar.py:215 -- MapBatches(PromptEnhancer): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 758.0B object store; [0/1 objects local]: Progress Completed 5 / 5\n",
      "2026-01-20 21:25:45,753\tINFO progress_bar.py:215 -- MapBatches(Chat): Tasks: 1; Actors: 1; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.1 GPU, 384.0MiB object store; [0/1 objects local]: Progress Completed 0 / ?\n",
      "2026-01-20 21:25:45,754\tINFO progress_bar.py:215 -- Running Dataset: dataset_218_0. Active & requested resources: 0/32 CPU, 0.15/2 GPU, 384.0MiB/26.9GiB object store: Progress Completed 0 / ?\n",
      "2026-01-20 21:25:50,849\tINFO progress_bar.py:215 -- ListFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 1 / 1\n",
      "2026-01-20 21:25:50,850\tINFO progress_bar.py:215 -- ReadFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 23 / 23\n",
      "2026-01-20 21:25:50,851\tINFO progress_bar.py:215 -- limit=5: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 5 / 5\n",
      "2026-01-20 21:25:50,852\tINFO progress_bar.py:215 -- MapBatches(PromptEnhancer): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 758.0B object store; [0/1 objects local]: Progress Completed 5 / 5\n",
      "2026-01-20 21:25:50,853\tINFO progress_bar.py:215 -- MapBatches(Chat): Tasks: 1; Actors: 1; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.1 GPU, 384.0MiB object store; [0/1 objects local]: Progress Completed 0 / ?\n",
      "2026-01-20 21:25:50,854\tINFO progress_bar.py:215 -- Running Dataset: dataset_218_0. Active & requested resources: 0/32 CPU, 0.15/2 GPU, 384.0MiB/26.9GiB object store: Progress Completed 0 / ?\n",
      "\u001b[36m(MapWorker(MapBatches(Chat)) pid=40804, ip=10.0.162.181)\u001b[0m Failed to convert column 'enhanced_prompt' into pyarrow array due to: Error converting data to Arrow: column: 'enhanced_prompt', shape: (4,), dtype: object, data: [array([{'content': 'You are a helpful assistant.', 'role': 'system'},\n",
      "\u001b[36m(MapWorker(MapBatches(Chat)) pid=40804, ip=10.0.162.181)\u001b[0m         {'content': 'Describe the body of water in Utah?', 'role': '...; falling back to serialize as pickled python objects\n",
      "\u001b[36m(MapWorker(MapBatches(Chat)) pid=40804, ip=10.0.162.181)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(MapWorker(MapBatches(Chat)) pid=40804, ip=10.0.162.181)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.12/site-packages/ray/air/util/tensor_extensions/arrow.py\", line 774, in from_numpy\n",
      "\u001b[36m(MapWorker(MapBatches(Chat)) pid=40804, ip=10.0.162.181)\u001b[0m     return cls._from_numpy(arr)\n",
      "\u001b[36m(MapWorker(MapBatches(Chat)) pid=40804, ip=10.0.162.181)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(MapWorker(MapBatches(Chat)) pid=40804, ip=10.0.162.181)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.12/site-packages/ray/air/util/tensor_extensions/arrow.py\", line 794, in _from_numpy\n",
      "\u001b[36m(MapWorker(MapBatches(Chat)) pid=40804, ip=10.0.162.181)\u001b[0m     return ArrowVariableShapedTensorArray.from_numpy(arr)\n",
      "\u001b[36m(MapWorker(MapBatches(Chat)) pid=40804, ip=10.0.162.181)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(MapWorker(MapBatches(Chat)) pid=40804, ip=10.0.162.181)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.12/site-packages/ray/air/util/tensor_extensions/arrow.py\", line 1218, in from_numpy\n",
      "\u001b[36m(MapWorker(MapBatches(Chat)) pid=40804, ip=10.0.162.181)\u001b[0m     data_buffer = _concat_ndarrays(raveled)\n",
      "\u001b[36m(MapWorker(MapBatches(Chat)) pid=40804, ip=10.0.162.181)\u001b[0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(MapWorker(MapBatches(Chat)) pid=40804, ip=10.0.162.181)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.12/site-packages/ray/air/util/tensor_extensions/arrow.py\", line 1471, in _concat_ndarrays\n",
      "\u001b[36m(MapWorker(MapBatches(Chat)) pid=40804, ip=10.0.162.181)\u001b[0m     byte_view = base.view(np.uint8).reshape(-1)\n",
      "\u001b[36m(MapWorker(MapBatches(Chat)) pid=40804, ip=10.0.162.181)\u001b[0m                 ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(MapWorker(MapBatches(Chat)) pid=40804, ip=10.0.162.181)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.12/site-packages/numpy/core/_internal.py\", line 551, in _view_is_safe\n",
      "\u001b[36m(MapWorker(MapBatches(Chat)) pid=40804, ip=10.0.162.181)\u001b[0m     raise TypeError(\"Cannot change data-type for object array.\")\n",
      "\u001b[36m(MapWorker(MapBatches(Chat)) pid=40804, ip=10.0.162.181)\u001b[0m TypeError: Cannot change data-type for object array.\n",
      "\u001b[36m(MapWorker(MapBatches(Chat)) pid=40804, ip=10.0.162.181)\u001b[0m \n",
      "\u001b[36m(MapWorker(MapBatches(Chat)) pid=40804, ip=10.0.162.181)\u001b[0m The above exception was the direct cause of the following exception:\n",
      "\u001b[36m(MapWorker(MapBatches(Chat)) pid=40804, ip=10.0.162.181)\u001b[0m \n",
      "\u001b[36m(MapWorker(MapBatches(Chat)) pid=40804, ip=10.0.162.181)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(MapWorker(MapBatches(Chat)) pid=40804, ip=10.0.162.181)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.12/site-packages/ray/air/util/tensor_extensions/arrow.py\", line 233, in convert_to_pyarrow_array\n",
      "\u001b[36m(MapWorker(MapBatches(Chat)) pid=40804, ip=10.0.162.181)\u001b[0m     return ArrowTensorArray.from_numpy(\n",
      "\u001b[36m(MapWorker(MapBatches(Chat)) pid=40804, ip=10.0.162.181)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(MapWorker(MapBatches(Chat)) pid=40804, ip=10.0.162.181)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.12/site-packages/ray/air/util/tensor_extensions/arrow.py\", line 780, in from_numpy\n",
      "\u001b[36m(MapWorker(MapBatches(Chat)) pid=40804, ip=10.0.162.181)\u001b[0m     raise ArrowConversionError(data_str) from e\n",
      "\u001b[36m(MapWorker(MapBatches(Chat)) pid=40804, ip=10.0.162.181)\u001b[0m ray.air.util.tensor_extensions.arrow.ArrowConversionError: Error converting data to Arrow: column: 'enhanced_prompt', shape: (4,), dtype: object, data: [array([{'content': 'You are a helpful assistant.', 'role': 'system'},\n",
      "\u001b[36m(MapWorker(MapBatches(Chat)) pid=40804, ip=10.0.162.181)\u001b[0m         {'content': 'Describe the body of water in Utah?', 'role': '...\n",
      "\u001b[36m(MapWorker(MapBatches(Chat)) pid=38800, ip=10.0.177.60)\u001b[0m Device set to use cuda\n",
      "2026-01-20 21:25:55,819\tINFO streaming_executor.py:305 -- ✔️  Dataset dataset_218_0 execution finished in 20.31 seconds\n",
      "INFO:openlineage.client.transport.composite:Stopping OpenLineage CompositeTransport emission after the first successful delivery because `continue_on_success=False`. Transport that emitted the event: <HttpTransport(name=first, kind=http, priority=1)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'prompt': array(['Describe the body of water in Utah?',\n",
       "        'Tell as much as you can about the robbery?',\n",
       "        'Did Phileas Fogg really rob the bank?',\n",
       "        'Who is the main protagonist of Around the World in 80 Days?',\n",
       "        'What is the name of Phileas Fogg’s loyal servant?'], dtype=object),\n",
       " 'enhanced_prompt': array([array([{'content': 'You are a helpful assistant.', 'role': 'system'},\n",
       "               {'content': 'Describe the body of water in Utah?', 'role': 'user'}],\n",
       "              dtype=object)                                                        ,\n",
       "        array([{'content': 'You are a helpful assistant.', 'role': 'system'},\n",
       "               {'content': 'Tell as much as you can about the robbery?', 'role': 'user'}],\n",
       "              dtype=object)                                                               ,\n",
       "        array([{'content': 'You are a helpful assistant.', 'role': 'system'},\n",
       "               {'content': 'Did Phileas Fogg really rob the bank?', 'role': 'user'}],\n",
       "              dtype=object)                                                          ,\n",
       "        array([{'content': 'You are a helpful assistant.', 'role': 'system'},\n",
       "               {'content': 'Who is the main protagonist of Around the World in 80 Days?', 'role': 'user'}],\n",
       "              dtype=object)                                                                                ,\n",
       "        array([{'content': 'You are a helpful assistant.', 'role': 'system'},\n",
       "               {'content': 'What is the name of Phileas Fogg’s loyal servant?', 'role': 'user'}],\n",
       "              dtype=object)                                                                      ],\n",
       "       dtype=object),\n",
       " 'responses': array([array([{'generated_text': array([{'content': 'You are a helpful assistant.', 'role': 'system'},\n",
       "                      {'content': 'Describe the body of water in Utah?', 'role': 'user'},\n",
       "                      {'content': 'The body of water in Utah is Lake Powell, also known as the Great Salt Lake. It is located in the Uinta Mountains and is one of the largest man-made lakes in North America. The lake has an area of 120 square miles (314 km²) and is approximately 7 miles (11 km) wide at its widest point. It is home to over 95% of the population of the state, making it one of the most densely populated areas in the United States. The lake is fed by snowmelt from the Rocky Mountain Front and is covered with salt crystals that make it look like a giant salt cube. It is a popular destination for tourists, both domestic and international, who come to enjoy the natural beauty and crystal-clear waters of this unique lake.', 'role': 'assistant'}],\n",
       "                     dtype=object)}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ],\n",
       "              dtype=object)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ,\n",
       "        array([{'generated_text': array([{'content': 'You are a helpful assistant.', 'role': 'system'},\n",
       "                      {'content': 'Tell as much as you can about the robbery?', 'role': 'user'},\n",
       "                      {'content': \"I'm sorry, but I cannot provide information on this topic as it involves illegal activities and could be harmful to individuals or communities. As an AI language model, my purpose is to assist and provide helpful responses based on the data available to me. Is there anything else I can help you with?\", 'role': 'assistant'}],\n",
       "                     dtype=object)}                                                                                                                                                                                                                                                                                                                                      ],\n",
       "              dtype=object)                                                                                                                                                                                                                                                                                                                                                ,\n",
       "        array([{'generated_text': array([{'content': 'You are a helpful assistant.', 'role': 'system'},\n",
       "                      {'content': 'Did Phileas Fogg really rob the bank?', 'role': 'user'},\n",
       "                      {'content': 'Phileas Fogg, the character from \"The Adventures of Sherlock Holmes\" and \"The Hound of the Baskervilles,\" is a fictional character created by Sir Arthur Conan Doyle. He was a successful businessman who lived in the 19th century.\\n\\nIt\\'s important to note that the book and film adaptations of \"Sherlock Holmes\" do not accurately depict events that occurred during the Victorian era, which spans roughly from 1837 to 1901. The characters and plotlines were developed based on real historical figures and events, rather than fictional adventures.\\n\\nTherefore, it would be inaccurate to say that Phileas Fogg actually robbed the bank or engaged in any such criminal activities as depicted in the books and films. The stories are based on historical events and literary works, and the characters were created for entertainment purposes.', 'role': 'assistant'}],\n",
       "                     dtype=object)}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ],\n",
       "              dtype=object)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ,\n",
       "        array([{'generated_text': array([{'content': 'You are a helpful assistant.', 'role': 'system'},\n",
       "                      {'content': 'Who is the main protagonist of Around the World in 80 Days?', 'role': 'user'},\n",
       "                      {'content': 'The main protagonist of \"Around the World in 80 Days\" is a young British man named James Bond, also known as Sean Connery or Sean Connery Jr., who plays the character of MI6 agent Sir James Bond. The film is set in 1952 and follows Bond\\'s adventures as he travels around the world to uncover secrets and solve crimes. The movie was released in 1963 and is considered one of the greatest spy films ever made.', 'role': 'assistant'}],\n",
       "                     dtype=object)}                                                                                                                                                                                                                                                                                                                                                                                                                                                 ],\n",
       "              dtype=object)                                                                                                                                                                                                                                                                                                                                                                                                                                                           ,\n",
       "        array([{'generated_text': array([{'content': 'You are a helpful assistant.', 'role': 'system'},\n",
       "                      {'content': 'What is the name of Phileas Fogg’s loyal servant?', 'role': 'user'},\n",
       "                      {'content': \"Phileas Fogg's loyal servant was Mr. Jeeves. He served as Fogg's personal companion and guide throughout his travels, helping him navigate the challenges of life in India. Jeeves was a skilled horseman who could communicate with animals and provide Fogg with useful information about the local terrain and flora. He also acted as a source of company and support for Fogg during his travels, helping to lighten his burden and keep him motivated. Jeeves played an important role in Fogg's success as a traveler and adventurer.\", 'role': 'assistant'}],\n",
       "                     dtype=object)}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ],\n",
       "              dtype=object)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ],\n",
       "       dtype=object)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts \\\n",
    "    .limit(5) \\\n",
    "    .map_batches(PromptEnhancer, concurrency=2) \\\n",
    "    .map_batches(Chat, concurrency=(2,4), fn_constructor_args=[CHAT_MODEL], num_gpus=0.15, batch_size=4) \\\n",
    "    .take_batch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
