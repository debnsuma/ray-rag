{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fd443a5-c9d3-4b6f-ad72-59c1eba1d112",
   "metadata": {},
   "source": [
    "<h2 style=\"color: #0f2027; background: linear-gradient(90deg, #43cea2 0%, #185a9d 100%); padding: 12px 0; border-radius: 8px; text-align:center; font-size: 2rem; letter-spacing: 1px;\">\n",
    "   <span style=\"color: #fff;\"> Introduction to Ray Core</span> \n",
    "</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd84432-84b0-426e-8546-42f33804f2fa",
   "metadata": {},
   "source": [
    "This notebook provides a step-by-step introduction to Ray Tasks, the fundamental building block of Ray that enables distributed computing.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<b> Here is the roadmap for this notebook </b>\n",
    "\n",
    "<ol>\n",
    "  <li>Overview</li>\n",
    "  <li>Creating Remote Functions</li>\n",
    "  <li>Executing Remote Functions</li>\n",
    "  <li>Getting Results</li>\n",
    "  <li>Putting It All Together</li>\n",
    "  <li>Object store and Memory model</li>\n",
    "  <li>Chaining Tasks and Passing Data</li>\n",
    "  <li>Task retries</li>\n",
    "  <li>Task Runtime Environments</li>\n",
    "  <li>Resource allocation and management</li>\n",
    "  <li>Pipeline data processing and waiting for results</li>\n",
    "  <li>Ray Actors</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08cc42c",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98399ea9-933a-452f-be3f-bc1535006443",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import ray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff9ad39-11cb-495e-964f-a05a95159bea",
   "metadata": {},
   "source": [
    "## 1. Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c91bfd",
   "metadata": {},
   "source": [
    "### Ray Core at a glance\n",
    "\n",
    "- **Scales your code** across many CPU cores, machines, and accelerators.  \n",
    "- **Schedules arbitrary task graphs** thanks to its distributed scheduler.\n",
    "- **Hides distributed-system overhead** with built-ins for  \n",
    "  - fast data serialization and transfer,  \n",
    "  - smart task placement, \n",
    "  - distributed memory & reference counting.\n",
    "\n",
    "Ray’s higher-level libraries build on Ray Core to offer ready-made APIs for common workloads.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c356de6",
   "metadata": {},
   "source": [
    "## 2. Creating Remote Functions\n",
    "\n",
    "The first step in using Ray is to create remote functions. A remote function is a regular Python function that can be executed on any process in your cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8b00c1-d320-4b62-a35b-08bea2e848e3",
   "metadata": {},
   "source": [
    "Given a simple Python function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc20546b-510d-4885-82fa-5d12503d52f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.add(a, b)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add(a, b):\n",
    "    return a + b\n",
    "\n",
    "add"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46f71e2",
   "metadata": {},
   "source": [
    "Decorate the function with `@ray.remote` to turn it into a remote function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cb578bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ray.remote_function.RemoteFunction at 0x7d2358be74a0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@ray.remote\n",
    "def remote_add(a, b):\n",
    "    return a + b\n",
    "\n",
    "remote_add"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03627df",
   "metadata": {},
   "source": [
    "## 3. Executing Remote Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4479f92",
   "metadata": {},
   "source": [
    "Native python functions are invoked by calling them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d026c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add(1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfd3ad7-0d0e-4313-82d7-4d36f2e9537b",
   "metadata": {},
   "source": [
    "Remote ray functions are executed as tasks by calling them with `.remote()` suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7f0c8a3-f456-4594-a994-0e5a528c3b78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-08 17:49:22,657\tINFO worker.py:1833 -- Connecting to existing Ray cluster at address: 10.0.36.30:6379...\n",
      "2026-01-08 17:49:22,668\tINFO worker.py:2004 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32mhttps://session-zhee2uzsi3lhk3sdl5dvqc8x4m.i.anyscaleuserdata.com \u001b[39m\u001b[22m\n",
      "2026-01-08 17:49:22,698\tINFO packaging.py:380 -- Pushing file package 'gcs://_ray_pkg_65ba782e3db6ef7574cdbf3355d281d661917131.zip' (9.97MiB) to Ray cluster...\n",
      "2026-01-08 17:49:22,735\tINFO packaging.py:393 -- Successfully pushed file package 'gcs://_ray_pkg_65ba782e3db6ef7574cdbf3355d281d661917131.zip'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ObjectRef(3ca0590f168eaec5ffffffffffffffffffffffff0500000001000000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remote_add.remote(1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b65a5bf-999a-4461-9ece-4ff87ed50d70",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "  <strong><a href=\"https://docs.ray.io/en/latest/ray-core/key-concepts.html#tasks\" target=\"_blank\">Tasks</a></strong> is a remote, stateless Python function invokation.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b79fec",
   "metadata": {},
   "source": [
    "Here is what happens when you call `{remote_function}.remote`:\n",
    "1. Ray schedules the function execution as a task in a separate process in the cluster\n",
    "2. Ray returns an `ObjectRef` (a reference to the future result) to you **immediately** \n",
    "3. The cluster executes the actual computation in the background\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c939071-2454-4042-8136-75ffbbf6cce0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectRef(4482c0d3e15a41a8ffffffffffffffffffffffff0500000001000000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref = remote_add.remote(1, 2)\n",
    "ref"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb4362b",
   "metadata": {},
   "source": [
    "Here is a map of how Python code is translated into Ray tasks.\n",
    "\n",
    "<img src=\"https://anyscale-materials.s3.us-west-2.amazonaws.com/ray-core/python_to_ray_task_map_v2.png\" alt=\"Python to Ray Task Map\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc911f58",
   "metadata": {},
   "source": [
    "## 4. Getting Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7928ca98-dc51-4ecf-b757-92996dd0c69a",
   "metadata": {},
   "source": [
    "If we want to wait (block) and retrieve the corresponding object, we can use `ray.get`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a564c830-d30d-4d4c-adb5-ee12adee605b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.get(ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d550f58a",
   "metadata": {},
   "source": [
    "## 5. Putting It All Together\n",
    "\n",
    "Here are the three steps:\n",
    "1. Create the remote function\n",
    "2. Execute it remotely\n",
    "3. Get the result when needed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da412f5-133a-441b-8734-b96f56389f05",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "__Activity: define and invoke a Ray task__\n",
    "\n",
    "Define a remote function `sqrt_add` that accepts two arguments and performs the following steps:\n",
    "1. computes the square-root of the first\n",
    "2. adds the second\n",
    "3. returns the result\n",
    "\n",
    "Execute it with 2 different sets of parameters and collect the results\n",
    "\n",
    "```python\n",
    "# Hint: define the below as a remote function\n",
    "def sqrt_add(a, b):\n",
    "    ... \n",
    "\n",
    "# Hint: invoke it as a remote task and collect the results\n",
    "```\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ace32382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.414213562373095, 23.162277660168378, 56.324555320336756]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your solution here\n",
    "import math \n",
    "\n",
    "@ray.remote\n",
    "def sqrt_add(a,b):\n",
    "    return math.sqrt(a) + b\n",
    "\n",
    "\n",
    "inputs = [(2, 3), (10, 20), (40, 50)]\n",
    "refs = [sqrt_add.remote(*input) for input in inputs]\n",
    "ray.get(refs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fe7b54",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary> Click to see solution </summary>\n",
    "\n",
    "```python\n",
    "import math\n",
    "\n",
    "@ray.remote\n",
    "def sqrt_add(a, b):\n",
    "    return math.sqrt(a) + b\n",
    "\n",
    "ray.get([sqrt_add.remote(2, 3), sqrt_add.remote(5, 4)])\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae13f94-7307-4a43-ad55-bfa8df9c6cdb",
   "metadata": {},
   "source": [
    "### 4.1. Note about Ray ID Specification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6948957",
   "metadata": {},
   "source": [
    "IDs for tasks and objects are build according to the [ID specification in Ray](https://github.com/ray-project/ray/blob/master/src/ray/design_docs/id_specification.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f83ee09e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectRef(68d7b3a94be6e983ffffffffffffffffffffffff0500000001000000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70a1a1ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JobID(05000000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refs[0].job_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4b8b3c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaskID(68d7b3a94be6e983ffffffffffffffffffffffff05000000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refs[0].task_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28c6d1d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__await__',\n",
       " '__bytes__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pyx_vtable__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '_on_completed',\n",
       " '_set_id',\n",
       " 'as_future',\n",
       " 'binary',\n",
       " 'call_site',\n",
       " 'from_binary',\n",
       " 'from_hex',\n",
       " 'from_random',\n",
       " 'future',\n",
       " 'hex',\n",
       " 'is_nil',\n",
       " 'job_id',\n",
       " 'nil',\n",
       " 'owner_address',\n",
       " 'redis_shard_hash',\n",
       " 'size',\n",
       " 'task_id',\n",
       " 'tensor_transport']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(refs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84c4e70",
   "metadata": {},
   "source": [
    "### 4.2. Anti-pattern: Calling ray.get in a loop harms parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dbf506-7cd4-4408-b4b6-91b1defeef9e",
   "metadata": {},
   "source": [
    "|<img src=\"https://assets-training.s3.us-west-2.amazonaws.com/ray-core/ray-core/ray-get-in-a-loop.png\" width=\"700px\" loading=\"lazy\">|\n",
    "|:--|\n",
    "|ray.get() is a blocking call. Avoid calling it on every item (left panel). Calling only on the final result improves performance (right panel).|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daeed79b-fb6f-45c3-a3c1-2f501ff56241",
   "metadata": {},
   "source": [
    "When trying to collect results for multiple remote function invocations (tasks), don't block and wait for each one individually. Let's consider this remote function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4322b5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def expensive_square(x):\n",
    "    time.sleep(5)\n",
    "    return x**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0405e415-06da-462f-8d5c-f8b6f0a460c2",
   "metadata": {},
   "source": [
    "This implementation will block for each item in the loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "907ed0b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 4, 9]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for item in range(4):\n",
    "    output = ray.get(expensive_square.remote(item))\n",
    "    results.append(output)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abdcf63",
   "metadata": {},
   "source": [
    "Schedule all remote calls, which are then processed in parallel. After scheduling the work, we can then request all the results at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7e498de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 4, 9]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refs = []\n",
    "for j in range(4):\n",
    "    refs.append(expensive_square.remote(j))\n",
    "results = ray.get(refs)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837090c0-cd19-4678-bca8-99270a9a20f7",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Read more about this <strong><a href=\"https://docs.ray.io/en/latest/ray-core/patterns/ray-get-loop.html\" target=\"_blank\">anti-pattern</a></strong>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0c32ae-d8e0-4f41-804e-1e8f30cde987",
   "metadata": {},
   "source": [
    "## 6. Object store and Memory model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b74deb4-4f18-4d79-8bfd-2ca864882005",
   "metadata": {},
   "source": [
    "Each worker node has its own object store, and collectively, these form a shared object store across the cluster.\n",
    "\n",
    "Remote objects are immutable. That is, their values cannot be changed after creation. This allows remote objects to be replicated in multiple object stores without needing to synchronize the copies.\n",
    "\n",
    "|<img src=\"https://assets-training.s3.us-west-2.amazonaws.com/ray-core/ray-core/ray-cluster.png\" width=\"700px\" loading=\"lazy\">|\n",
    "|:--|\n",
    "|A Ray cluster with a head node and two worker nodes. Highlighted in orange is distributed object store.|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33078fc-7246-41ab-87c3-2be7856bc9f2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "  <strong><a href=\"https://docs.ray.io/en/latest/ray-core/key-concepts.html#objects\" target=\"_blank\">Object</a></strong> - tasks and actors create and work with remote objects, which can be stored anywhere in a cluster. These objects are accessed using <strong>ObjectRef</strong> and are cached in a distributed shared-memory <strong>object store</strong>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e644a8d5-db13-4782-918a-589842d2468e",
   "metadata": {},
   "source": [
    "Let's consider following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7ab638f-35d4-4a7c-99f3-426544680025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "large_matrix has: 2.00 GB\n"
     ]
    }
   ],
   "source": [
    "large_matrix = np.random.rand(2, 1024, 1024, 1024//8) # approx. 2 GB\n",
    "size_in_bytes = sys.getsizeof(large_matrix)\n",
    "\n",
    "print(f\"large_matrix has: {size_in_bytes/1024/1024/1024:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f739cd4-1321-4797-9d16-41d250072f21",
   "metadata": {},
   "source": [
    "Add an object to the object store using `ray.put()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "413522e0-1f76-4b96-af72-ac5746beb201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectRef(00ffffffffffffffffffffffffffffffffffffff0500000001e1f505)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_ref = ray.put(large_matrix)\n",
    "obj_ref"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983baa95-8e4b-4b26-a50b-068f6a99cd6f",
   "metadata": {},
   "source": [
    "Use the `ray.get()` method to fetch the result of a remote object from an object ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4bc5d9d-8616-41b8-9619-8067187e617b",
   "metadata": {},
   "outputs": [],
   "source": [
    "large_mat_from_object_store = ray.get(obj_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca22214",
   "metadata": {},
   "source": [
    "While the contents are the same, the object store contains a copy of the array which is not the same memory location. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe680c84-9483-492b-956a-2d999fdddd28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(large_mat_from_object_store, large_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc0cde4",
   "metadata": {},
   "source": [
    "Array in store is in shared memory whereas array in notebook is local to the notebook process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e4d4978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137589151124144, 137589150762448)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(large_mat_from_object_store), id(large_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a991d4b-d621-42ae-8d9e-c104632cc753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_mat_from_object_store is large_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d888210a-e354-4fd1-87af-def070c39adf",
   "metadata": {},
   "source": [
    "### 6.1 Pattern: Pass large objects **by reference**\n",
    "\n",
    "Ray distinguishes between a **value** and an **Object Ref** when you pass arguments to remote functions:\n",
    "\n",
    "* **Value** → Ray serializes the data and writes a fresh copy to the object store for every call.\n",
    "* **Object Ref** → Ray forwards only a lightweight ID; the worker fetches the data once and reuses it.\n",
    "\n",
    "Upload big, read‑only objects once, then circulate their `ObjectRef` to every consumer task. This avoids repeated serialization, network traffic, and object‑store pressure.\n",
    "\n",
    "Pass by value only for small literals (< 100 KiB); otherwise, pass by reference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "abecf347-7f03-4e31-b576-ccf0123afcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "large_ref = ray.put(np.random.rand(1000, 1000))  # Approx. 8 MB -> place in object store\n",
    "\n",
    "\n",
    "@ray.remote\n",
    "def compute_sum(x):\n",
    "    return int(x.sum())\n",
    "\n",
    "\n",
    "# all tasks use same ObjectRef minimizing copies (memory efficient)\n",
    "results = ray.get([compute_sum.remote(large_ref) for _ in range(100)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbe06d8",
   "metadata": {},
   "source": [
    "### 6.2. Ray memory model\n",
    "\n",
    "Ray manages memory in several ways to efficiently handle distributed tasks:\n",
    "\n",
    "1. **Heap memory**:\n",
    "   - Used by workers to execute tasks and actors.\n",
    "   - Used to store small objects (less than 100KB) and Ray metadata.\n",
    "   - High memory pressure can cause Ray to terminate some tasks to free up resources.\n",
    "\n",
    "2. **Shared memory (Object Store)**:\n",
    "   - Serves as the medium for passing data between tasks.\n",
    "   - Large objects (greater than 100KB) are stored in a shared memory space, using up to 30% of a node's memory.\n",
    "   - If more space is needed, objects can be spilled to disk or stored on disk in a slower-access format.\n",
    "\n",
    "Here is a diagram showing a horizontal slicing of a node's memory.\n",
    "\n",
    "<img src=\"https://docs.ray.io/en/latest/_images/memory.svg\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce026bdc",
   "metadata": {},
   "source": [
    "### 6.3. Example: Producer-consumer pattern with numpy arrays\n",
    "\n",
    "This example demonstrates how Ray transfers data in the distributed object store. The `producer_task` creates a 4 GiB numpy array, and the `consumer_task` accesses it with zero-copy deserialization when on the same node:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e5ce085",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def producer_task(size_mb: int = 4 * 1024) -> np.ndarray:\n",
    "    array = np.random.rand((1024**2 * size_mb // 8)).astype(np.float64)\n",
    "    return array\n",
    "\n",
    "\n",
    "@ray.remote\n",
    "def consumer_task(array: np.ndarray) -> None:\n",
    "    assert isinstance(array, np.ndarray)\n",
    "    assert not array.flags.owndata  # Confirms zero-copy\n",
    "\n",
    "arr_ref = producer_task.remote()  # Produce a 4 GiB array\n",
    "output_ref = consumer_task.remote(arr_ref)  # Pass ObjectRef to consumer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b738774",
   "metadata": {},
   "source": [
    "**What happens under the hood:**\n",
    "\n",
    "1. **Producer task** creates the array in heap memory, then Ray stores it in the shared object store (large objects > 100KB)\n",
    "2. **Consumer task** receives the `ObjectRef` and directly accesses the array from shared memory with zero-copy deserialization (if on same node)\n",
    "3. If tasks run on different nodes, Ray copies the array across the network only once\n",
    "\n",
    "<img src=\"https://anyscale-materials.s3.us-west-2.amazonaws.com/ray-data-deep-dive/producer-consumer-object-store-v2.png\" width=\"600\">\n",
    "\n",
    "To see memory usage in action, run this inspection script:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73a3c9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-08 17:49:56,366\tINFO worker.py:1833 -- Connecting to existing Ray cluster at address: 10.0.36.30:6379...\n",
      "2026-01-08 17:49:56,377\tINFO worker.py:2004 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32mhttps://session-zhee2uzsi3lhk3sdl5dvqc8x4m.i.anyscaleuserdata.com \u001b[39m\u001b[22m\n",
      "2026-01-08 17:49:56,406\tINFO packaging.py:380 -- Pushing file package 'gcs://_ray_pkg_65ba782e3db6ef7574cdbf3355d281d661917131.zip' (9.97MiB) to Ray cluster...\n",
      "2026-01-08 17:49:56,440\tINFO packaging.py:393 -- Successfully pushed file package 'gcs://_ray_pkg_65ba782e3db6ef7574cdbf3355d281d661917131.zip'.\n",
      "\u001b[36m(producer_task pid=4777, ip=10.0.30.21)\u001b[0m producer_task: At start\n",
      "\u001b[36m(producer_task pid=4777, ip=10.0.30.21)\u001b[0m RSS : 91.7578125 MiB\n",
      "\u001b[36m(producer_task pid=4777, ip=10.0.30.21)\u001b[0m Shared memory: 44.125 MiB\n",
      "\u001b[36m(producer_task pid=4777, ip=10.0.30.21)\u001b[0m Heap memory (RSS - Shared): 47.6328125 MiB\n",
      "\u001b[36m(producer_task pid=4777, ip=10.0.30.21)\u001b[0m ------------------------------\n",
      "\u001b[36m(producer_task pid=4777, ip=10.0.30.21)\u001b[0m \n",
      "\u001b[36m(producer_task pid=4777, ip=10.0.30.21)\u001b[0m producer_task: After creating array of size 4.00 GiB\n",
      "\u001b[36m(producer_task pid=4777, ip=10.0.30.21)\u001b[0m RSS : 4188.5546875 MiB\n",
      "\u001b[36m(producer_task pid=4777, ip=10.0.30.21)\u001b[0m Shared memory: 44.375 MiB\n",
      "\u001b[36m(producer_task pid=4777, ip=10.0.30.21)\u001b[0m Heap memory (RSS - Shared): 4144.1796875 MiB\n",
      "\u001b[36m(producer_task pid=4777, ip=10.0.30.21)\u001b[0m ------------------------------\n",
      "\u001b[36m(producer_task pid=4777, ip=10.0.30.21)\u001b[0m \n",
      "\u001b[36m(consumer_task pid=4777, ip=10.0.30.21)\u001b[0m consumer_task: At start\n",
      "\u001b[36m(consumer_task pid=4777, ip=10.0.30.21)\u001b[0m RSS : 4221.21875 MiB\n",
      "\u001b[36m(consumer_task pid=4777, ip=10.0.30.21)\u001b[0m Shared memory: 4164.375 MiB\n",
      "\u001b[36m(consumer_task pid=4777, ip=10.0.30.21)\u001b[0m Heap memory (RSS - Shared): 56.84375 MiB\n",
      "\u001b[36m(consumer_task pid=4777, ip=10.0.30.21)\u001b[0m ------------------------------\n",
      "\u001b[36m(consumer_task pid=4777, ip=10.0.30.21)\u001b[0m \n"
     ]
    }
   ],
   "source": [
    "!python code/memory_inspection.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d3d122",
   "metadata": {},
   "source": [
    "#### On zero-copy deserialization\n",
    "\n",
    "Ray uses **cloudpickle** for serialization and **pickle 5** for zero-copy deserialization. \n",
    "\n",
    "**How Ray transfers code and data:**\n",
    "\n",
    "1. **Code transfer (functions)**: Functions are pickled and stored in the Global Control Store (GCS), then cached for subsequent calls\n",
    "\n",
    "2. **Data transfer (arguments/return values)**:\n",
    "   - **Small objects (< 100 KB)**: Pickled and transferred inline with the task metadata\n",
    "   - **Large objects (> 100 KB)**: Stored in shared memory (object store), only the `ObjectRef` is transferred\n",
    "\n",
    "**Key performance characteristics:**\n",
    "\n",
    "- **Zero-copy benefits**: Works for contiguous numpy arrays and PyArrow arrays on the same node, enabling efficient read access without data copying. \n",
    "- **Zero-copy limitation**: Does not support PyTorch tensors or other array types\n",
    "- **Immutability**: Objects in the object store are **immutable once sealed**, enabling safe sharing across processes\n",
    "\n",
    "To read more about object serialization in Ray, see [this documentation page here](https://docs.ray.io/en/latest/ray-core/objects/serialization.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e6e46c",
   "metadata": {},
   "source": [
    "## 7. Chaining Tasks and Passing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d38a95-a92a-466a-8d0f-e84de66ea2a8",
   "metadata": {},
   "source": [
    "Let's say we now want to execute a graph of two tasks:\n",
    "1. Square a value using `expensive_square`\n",
    "2. Add 1 to the `expensive_square` result, by using `remote_add`\n",
    "\n",
    "This can be achieved without fetching an intermediate result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91323c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def expensive_square(x):\n",
    "    time.sleep(1)\n",
    "    return x**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe732f3c",
   "metadata": {},
   "source": [
    "This can be achieved without fetching an intermediate result.\n",
    "\n",
    "**❌ Anti-pattern:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40ee13b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st task\n",
    "square_ref = expensive_square.remote(2)\n",
    "square_value = ray.get(square_ref)  # wait to get the value\n",
    "\n",
    "# 2nd task\n",
    "sum_ref = remote_add.remote(1, square_value)  # pass value from 1st task\n",
    "sum_value = ray.get(sum_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0546d7",
   "metadata": {},
   "source": [
    "**✅ Better:** Chain the tasks by passing the `ObjectRef` directly to the second task:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "34aca7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "square_ref = expensive_square.remote(2)\n",
    "sum_ref = remote_add.remote(1, square_ref)  # Pass ObjectRef, not value!\n",
    "sum_value = ray.get(sum_ref)  # Wait only at the end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6800b77",
   "metadata": {},
   "source": [
    "**Why this is better:**\n",
    "- No unnecessary data transfer (ObjectRef is just an ID)\n",
    "- Ray automatically handles dependencies\n",
    "- Second task waits for first task to complete\n",
    "- More efficient scheduling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efa520d",
   "metadata": {},
   "source": [
    "## 8. Task retries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bb3e4b-e142-4718-9bc5-fb68ca833fc8",
   "metadata": {},
   "source": [
    "Let's consider two types of exceptions:\n",
    "1. **system errors** (e.g., Python-level exceptions)\n",
    "2. **application-level errors** (e.g., a machine fails)\n",
    "\n",
    "Ray will automatically **retry a task up to 3 times**, if it fails due to a system error (e.g., a worker node dies)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0c809f",
   "metadata": {},
   "source": [
    "Below task won't be retried by default because it's an application failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a7cb77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def incorrect_square(x: int, prob: float) -> int:\n",
    "    # Simulate potential failures\n",
    "    if random.random() < prob:  # % chance of failure\n",
    "        raise ValueError(\"Random failure\")\n",
    "    return x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da3941df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At least one of the tasks failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-08 17:50:08,920\tERROR worker.py:430 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::incorrect_square()\u001b[39m (pid=4160, ip=10.0.18.182)\n",
      "  File \"/tmp/ipykernel_10055/2967030291.py\", line 5, in incorrect_square\n",
      "ValueError: Random failure\n",
      "2026-01-08 17:50:08,921\tERROR worker.py:430 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::incorrect_square()\u001b[39m (pid=4161, ip=10.0.18.182)\n",
      "  File \"/tmp/ipykernel_10055/2967030291.py\", line 5, in incorrect_square\n",
      "ValueError: Random failure\n",
      "2026-01-08 17:50:08,922\tERROR worker.py:430 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::incorrect_square()\u001b[39m (pid=4159, ip=10.0.18.182)\n",
      "  File \"/tmp/ipykernel_10055/2967030291.py\", line 5, in incorrect_square\n",
      "ValueError: Random failure\n",
      "2026-01-08 17:50:08,923\tERROR worker.py:430 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::incorrect_square()\u001b[39m (pid=4163, ip=10.0.18.182)\n",
      "  File \"/tmp/ipykernel_10055/2967030291.py\", line 5, in incorrect_square\n",
      "ValueError: Random failure\n",
      "2026-01-08 17:50:08,924\tERROR worker.py:430 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::incorrect_square()\u001b[39m (pid=4384, ip=10.0.30.21)\n",
      "  File \"/tmp/ipykernel_10055/2967030291.py\", line 5, in incorrect_square\n",
      "ValueError: Random failure\n",
      "2026-01-08 17:50:08,925\tERROR worker.py:430 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::incorrect_square()\u001b[39m (pid=4385, ip=10.0.30.21)\n",
      "  File \"/tmp/ipykernel_10055/2967030291.py\", line 5, in incorrect_square\n",
      "ValueError: Random failure\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    ray.get([incorrect_square.remote(x=4, prob=0.5) for _ in range(10)])\n",
    "except ray.exceptions.RayTaskError:\n",
    "    print(\"At least one of the tasks failed\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c88e98-6526-424c-9f92-341b369b1c23",
   "metadata": {},
   "source": [
    "Ray let's you specify how to handle retries when an exception is encountered.\n",
    "\n",
    "Let's retry on `ValueError`, like below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae3bd41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote(retry_exceptions=[ValueError])\n",
    "def correct_square(x: int, prob: float) -> int:\n",
    "    # Simulate potential failures\n",
    "    if random.random() < prob:  # % chance of failure\n",
    "        raise ValueError(\"Random failure\")\n",
    "\n",
    "    return x**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09269628",
   "metadata": {},
   "source": [
    "Note we did not have to re-define the remote function, instead we can an update version using `.options`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efdd26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-08 17:50:09,082\tERROR worker.py:430 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::incorrect_square()\u001b[39m (pid=4424, ip=10.0.18.182)\n",
      "  File \"/tmp/ipykernel_10055/2967030291.py\", line 5, in incorrect_square\n",
      "ValueError: Random failure\n"
     ]
    }
   ],
   "source": [
    "correct_square_mod = correct_square.options(\n",
    "    retry_exceptions=[ValueError], max_retries=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9775c9",
   "metadata": {},
   "source": [
    "Let's try it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7cc09a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m Task correct_square failed. There are 9 retries remaining, so the task will be retried. Error: User exception:\n",
      "\u001b[36mray::correct_square()\u001b[39m (pid=4424, ip=10.0.18.182)\n",
      "  File \"/tmp/ipykernel_10055/991359300.py\", line 5, in correct_square\n",
      "ValueError: Random failure\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[16, 16, 16, 16, 16, 16, 16, 16, 16, 16]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    outputs = ray.get([correct_square_mod.remote(x=4, prob=0.5) for _ in range(10)])\n",
    "except ray.exceptions.RayTaskError:\n",
    "    print(\"At least one of the tasks failed\", flush=True)\n",
    "\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858e11aa",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Refer to the <strong><a href=\"https://docs.ray.io/en/latest/ray-core/tasks/retries.html\" target=\"_blank\">retries</a></strong> to learn more.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00383d23",
   "metadata": {},
   "source": [
    "## 9. Task Runtime Environments\n",
    "\n",
    "Runtime environments can be used on top of the prepared environment from the Ray Cluster to customize the execution of tasks.\n",
    "\n",
    "When setting up a worker process to run a task, Ray will first prepare the environment for the task.\n",
    "\n",
    "This includes things like:\n",
    "* installing dependencies\n",
    "* setting environment variables\n",
    "\n",
    "For example, we can set an environment variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "35d6e83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote(runtime_env={\"env_vars\": {\"my_custom_env\": \"prod\"}})\n",
    "def f():\n",
    "    env = os.environ[\"my_custom_env\"]\n",
    "    return f\"My custom env is {env}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0cf3ecad-0484-4345-b581-e96d522deb24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My custom env is prod'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.get(f.remote())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba453ac",
   "metadata": {},
   "source": [
    "## 10. Resource allocation and management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e14d73",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Here is the sequence of events when you submit a Ray task:\n",
    "\n",
    "<img src=\"https://anyscale-materials.s3.us-west-2.amazonaws.com/ray-core/task-submission_old.gif\" alt=\"Task Submission Sequence\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84badf43-ef05-4de6-be07-0a654bb98b7a",
   "metadata": {},
   "source": [
    "By default, Ray will schedule a task as long as there is at least one CPU available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80cdf05-3386-44ee-9da1-c1dfaedb82ac",
   "metadata": {},
   "source": [
    "In code this can be specified in the `ray.remote`, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e52ea5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote(num_cpus=1)\n",
    "def remote_add(a, b):\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569c8f47",
   "metadata": {},
   "source": [
    "However, these resource specifications are not enforced - i.e. they are entirely [logical and not physical](https://docs.ray.io/en/latest/ray-core/scheduling/resources.html#physical-resources-vs-logical-resources).\n",
    "\n",
    "This means that you can for instance perform multiprocessing ormultithreading within a task and oversubscribe to resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "936d7605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(mm pid=4896, ip=10.0.18.182)\u001b[0m Took 1.9162685871124268s\n"
     ]
    }
   ],
   "source": [
    "@ray.remote(num_cpus=1)\n",
    "def mm(n: int = 4000):\n",
    "    A = np.random.rand(n, n)\n",
    "    B = np.random.rand(n, n)\n",
    "\n",
    "    # Time the dot product\n",
    "    start = time.time()\n",
    "    np.dot(A, B)\n",
    "    end = time.time()\n",
    "    print(f\"Took {end - start}s\")\n",
    "    \n",
    "ray.get(mm.options(runtime_env={\"env_vars\": {\"OMP_NUM_THREADS\": \"1\"}}).remote())\n",
    "ray.get(mm.options(runtime_env={\"env_vars\": {\"OMP_NUM_THREADS\": \"8\"}}).remote())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1190416f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Note by default, Ray will set the `OMP_NUM_THREADS` environment variable to the number of CPUs in the cluster.\n",
    "\n",
    "Learn more about <strong><a href=\"https://docs.ray.io/en/latest/ray-core/scheduling/resources.html#physical-resources-and-logical-resources\" target=\"_blank\">physical resources and logical resources</a></strong>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324ecaef",
   "metadata": {},
   "source": [
    "### 10.1 Common options\n",
    "\n",
    "**Resource options:**\n",
    "- `num_cpus`: Number of CPUs (can be fractional, e.g., 0.5)\n",
    "- `num_gpus`: Number of GPUs (can be fractional)\n",
    "- `memory`: Memory in bytes\n",
    "- `resources`: Dict of custom resources\n",
    "\n",
    "**Fault tolerance options:**\n",
    "- `max_retries`: Max number of retries (default: 3 for system errors)\n",
    "- `retry_exceptions`: List of exception types to retry on\n",
    "\n",
    "**Execution options:**\n",
    "- `runtime_env`: Dict specifying runtime environment\n",
    "- `scheduling_strategy`: Control task placement\n",
    "- `name`: Name for debugging/monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3433fdf2-db23-4cad-8b22-9616a85e5138",
   "metadata": {},
   "source": [
    "### 10.2 Note on resources requests, available resources, configuring large clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b5e13b-0228-4dca-934e-bfc10b0e067d",
   "metadata": {},
   "source": [
    "<p>During the <em>scheduling stage</em>, Ray evaluates the <strong>resource requirements</strong> specified via the <code>@ray.remote</code> decorator or within the <code>resources={...}</code> argument. These requirements may include:</p>\n",
    "\n",
    "<ul>\n",
    "    <li><strong>CPU</strong> e.g., <code>@ray.remote(num_cpus=2)</code>)</li>\n",
    "    <li><strong>GPU</strong> e.g., <code>@ray.remote(num_gpus=1)</code>)</li>\n",
    "    <li><strong>Custom resources</strong>: User-defined custom resources like <code>\"TPU\"</code></li>\n",
    "    <li><strong>Memory</strong></li>\n",
    "</ul>\n",
    "\n",
    "<p>Ray's scheduler checks the <strong>resource specification</strong> (sometimes referred to as <strong>resource shape</strong>) to match tasks and actors with available resources in the cluster. If the exact resource combination is unavailable, Ray may autoscaler the cluster.</p>\n",
    "\n",
    "<p>You can inspect the current resource availability using:</p>\n",
    "<pre><code>\n",
    "ray.available_resources()\n",
    "</code></pre>\n",
    "\n",
    "<p>This returns a dictionary showing the currently available CPUs, GPUs, memory, and any custom resources, for example:</p>\n",
    "\n",
    "<pre><code>{'CPU': 24.0, 'GPU': 1.0, 'memory': 2147483648.0}</code></pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "084f3b86-3154-4b9a-add5-b8c38636f158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': 103079215104.0,\n",
       " 'anyscale/provider:aws': 3.0,\n",
       " 'anyscale/accelerator_shape:1xT4': 2.0,\n",
       " 'node:10.0.30.21': 1.0,\n",
       " 'object_store_memory': 17847714694.0,\n",
       " 'CPU': 16.0,\n",
       " 'anyscale/region:us-west-2': 3.0,\n",
       " 'accelerator_type:T4': 2.0,\n",
       " 'GPU': 2.0,\n",
       " 'anyscale/node-group:1xT4:8CPU-32GB': 2.0,\n",
       " 'anyscale/node-group:head': 1.0,\n",
       " 'node:__internal_head__': 1.0,\n",
       " 'node:10.0.36.30': 1.0,\n",
       " 'anyscale/cpu_only:true': 1.0,\n",
       " 'node:10.0.18.182': 1.0}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.available_resources()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95db62a-822a-41a9-83b2-c5136e4715a3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "<strong>Pattern:</strong> configure the head node to be unavailable for compute tasks.\n",
    "\n",
    "When scaling to large clusters, it's important to ensure that the <strong>head node</strong> does not handle any compute tasks. Users can indicate that the head node is unavailable for compute by setting its resources:\n",
    "\n",
    "```resources: {\"CPU\": 0}```\n",
    "\n",
    "Learn more about <strong><a href=\"https://docs.ray.io/en/latest/cluster/vms/user-guides/large-cluster-best-practices.html#configuring-the-head-node\" target=\"_blank\">configuring the head node</a></strong>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dd688e-4a16-4483-a473-185ef01c25e9",
   "metadata": {},
   "source": [
    "### 10.2. Fractional resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea6043b-1a09-4eca-8414-a95565150afb",
   "metadata": {},
   "source": [
    "Fractional resources allow Ray Tasks to request a fraction of a CPU or GPU (e.g., 0.5), enabling finer-grained resource allocation.\n",
    "\n",
    "Let's consider the above example again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "657e33c1-3a11-4992-80fc-cd850980b921",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote(num_cpus=0.5)\n",
    "def remote_add(a, b):\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d549f6",
   "metadata": {},
   "source": [
    "This means Ray will allow execution of 2x the number of CPUs on the machine to run the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "28b395b0-4c4c-4210-8dd5-a10cb1687d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectRef(7a636a2779a3d471ffffffffffffffffffffffff0500000001000000)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref = remote_add.remote(2, 3)\n",
    "ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6a6e06f1-8ffa-411b-890c-296c98be021e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.get(ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf294f1-10d8-41ee-bdbb-7c87118c71ad",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    Fractional resources include support for <strong><a href=\"https://docs.ray.io/en/latest/ray-core/scheduling/accelerators.html#fractional-accelerators\" target=\"_blank\">multiple accelerators</a></strong>, allowing users to load multiple smaller models onto a single GPU. This is especially useful for scenarios like model inference. Learn more about <strong><a href=\"https://docs.ray.io/en/latest/ray-core/scheduling/resources.html#fractional-resource-requirements\" target=\"_blank\">fractional resource requirements</a></strong>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4c0ec2",
   "metadata": {},
   "source": [
    "## 11. Pipeline data processing and waiting for results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecc9406-e8f9-4263-815a-3301a60dbef7",
   "metadata": {},
   "source": [
    "After launching a number of tasks, you may want to know which ones have finished executing without blocking on all of them. This could be achieved by `ray.wait()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ced3b1-18d1-4485-b075-589213d1cacb",
   "metadata": {},
   "source": [
    "|<img src=\"https://assets-training.s3.us-west-2.amazonaws.com/ray-core/ray-core/pipeline-data-processing.png\" width=\"400px\" loading=\"lazy\">|\n",
    "|:--|\n",
    "|(top panel) Execution timeline when using ray.get() to wait for all results before calling process results. (bottom panel) Execution timeline when using ray.wait() to process results as soon as they become available.|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e77d56d-fe64-4269-a66e-43c8429d5afb",
   "metadata": {},
   "source": [
    "Here are functions to match the above diagram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "006a1b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def do_some_work(x):\n",
    "    time.sleep(random.uniform(0, 4))  # Replace this with work you need to do.\n",
    "    return x\n",
    "\n",
    "\n",
    "def process_incremental(sum, result):\n",
    "    time.sleep(1)  # Replace this with some processing code.\n",
    "    return sum + result\n",
    "\n",
    "\n",
    "def process_results(results):\n",
    "    sum = 0\n",
    "    for x in results:\n",
    "        sum += process_incremental(sum, x)\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9898ca5a",
   "metadata": {},
   "source": [
    "This is the **naive approach:**, block until all tasks are complete and then process the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "473df4b6-4f94-4ce7-a559-0a1cb7a8f650",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(raylet, ip=10.0.30.21)\u001b[0m Spilled 8192 MiB, 2 objects, write throughput 454 MiB/s. Set RAY_verbose_spill_logs=0 to disable this message.\",\"component\":\"raylet\",\"filename\":\"local_object_manager.cc\",\"lineno\":259}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration = 24.28804039955139 \n",
      "result =  1048555\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "data_list = ray.get([do_some_work.remote(x) for x in range(20)])\n",
    "sum = process_results(data_list)\n",
    "print(\"duration =\", time.time() - start, \"\\nresult = \", sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f86c39e-8178-4296-854e-082f1302fabb",
   "metadata": {},
   "source": [
    "This is the **pipelined** approach, process items as soon as they become available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bc468ba0-4b11-41a1-89b1-7a21b9924ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration = 20.087604522705078 \n",
      "result =  190\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "result_ids = [do_some_work.remote(x) for x in range(20)]\n",
    "\n",
    "sum = 0\n",
    "while len(result_ids):\n",
    "    done_id, result_ids = ray.wait(result_ids)\n",
    "    sum = process_incremental(sum, ray.get(done_id[0]))\n",
    "\n",
    "print(\"duration =\", time.time() - start, \"\\nresult = \", sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f59714-5823-4575-949f-21f19ea0dba6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Read more about the <strong><a href=\"https://docs.ray.io/en/latest/ray-core/tips-for-first-time.html#tip-4-pipeline-data-processing\" target=\"_blank\">pipeline data processing</a></strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d03e83b-bc22-424d-9501-f8aacbca4c60",
   "metadata": {},
   "source": [
    "## 12. Ray Actors\n",
    "\n",
    "Actors extend the Ray API from functions (tasks) to classes.\n",
    "\n",
    "An actor is a stateful worker. When a new actor is instantiated, a new worker is created, and methods of the actor are scheduled on that specific worker and can access and mutate the state of that worker. Similarly to Ray Tasks, actors support CPU and GPU compute as well as fractional resources.\n",
    "\n",
    "Let's look at an example of an actor which maintains a running balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0500f797-7c77-4e68-a3d0-32c00544ee19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class Accounting:\n",
    "    def __init__(self):\n",
    "        self.total = 0\n",
    "    \n",
    "    def add(self, amount):\n",
    "        self.total += amount\n",
    "        \n",
    "    def remove(self, amount):\n",
    "        self.total -= amount\n",
    "        \n",
    "    def total(self):\n",
    "        return self.total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdbf7b6-14e2-41dc-996a-764c6f2f3b27",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "  <strong><a href=\"https://docs.ray.io/en/latest/ray-core/key-concepts.html#actors\" target=\"_blank\">Actor</a></strong> is a remote, stateful Python class.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58c3e32",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "The most common use case for actors is with state that is not mutated but is large enough that we may want to load it only once and ensure we can route calls to it over time, such as a large AI model.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad7a2da-0411-4e77-a371-3583a21c949e",
   "metadata": {},
   "source": [
    "Define an actor with the `@ray.remote` decorator and then use `<class_name>.remote()` ask Ray to construct and instance of this actor somewhere in the cluster.\n",
    "\n",
    "We get an actor handle which we can use to communicate with that actor, pass to other code, tasks, or actors, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4d9b1c79-fc12-4f59-8567-a04c4f11f379",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "acc = Accounting.remote()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd54012-0d2e-4f15-a07d-5b36f3ade524",
   "metadata": {},
   "source": [
    "We can send a message to an actor -- with RPC semantics -- by using `<handle>.<method_name>.remote()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b932c862-980f-440e-8e57-74cbc556bf4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectRef(756963cc1de4954040f50f2e5c482efea54133b90500000001000000)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc.total.remote()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325f56af-a8d1-482e-962c-2904bb757440",
   "metadata": {},
   "source": [
    "Not surprisingly, we get an object ref back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4213d804-0e3b-4ed1-a0b2-41681d375456",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.get(acc.total.remote())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775651a3-09c7-4992-80ed-b793e9a78f96",
   "metadata": {},
   "source": [
    "We can mutate the state inside this actor instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6a685a15-3844-4a9e-a243-8befe6b8c4fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectRef(186010f41212601640f50f2e5c482efea54133b90500000001000000)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc.add.remote(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "642b27e1-7dd8-4ef7-8ebb-f0c4ec856427",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectRef(3e0f2a001193943c40f50f2e5c482efea54133b90500000001000000)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc.remove.remote(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ad395cf9-b7f9-4dde-be12-b511de52c7fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.get(acc.total.remote())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d59a163-e93e-4348-860c-fcbc0be8018b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "__Activity: linear model inference__\n",
    "\n",
    "* Create an actor which applies a model to convert Celsius temperatures to Fahrenheit\n",
    "* The constructor should take model weights (w1 and w0) and store them as instance state\n",
    "* A convert method should take a scalar, multiply it by w1 then add w0 (weights retrieved from instance state) and then return the result\n",
    "\n",
    "\n",
    "```python\n",
    "# Hint: define the below as a remote actor\n",
    "class LinearModel:\n",
    "    def __init__(self, w0, w1):\n",
    "        # Hint: store the weights\n",
    "\n",
    "    def convert(self, celsius):\n",
    "        # Hint: convert the celsius temperature to Fahrenheit\n",
    "\n",
    "# Hint: create an instance of the LinearModel actor\n",
    "\n",
    "# Hint: convert 100 Celsius to Fahrenheit\n",
    "```\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b425dd5a-a48f-4ef2-bbcf-6be72cd5ce24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your solution here\n",
    "@ray.remote\n",
    "class LinearModel:\n",
    "    def __init__(self, w0, w1):\n",
    "        self.w0 = w0\n",
    "        self.w1 = w1\n",
    "\n",
    "    def convert(self, celsius):\n",
    "        result = self.w0 * celsius + self.w1 \n",
    "        return result\n",
    "\n",
    "# Hint: create an instance of the LinearModel actor\n",
    "model = LinearModel.remote(w0 = 9/5, w1 = 32)\n",
    "# Hint: convert 100 Celsius to Fahrenheit\n",
    "ray.get(model.convert.remote(100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a91503",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary> Click to see solution </summary>\n",
    "\n",
    "```python\n",
    "@ray.remote\n",
    "class LinearModel:\n",
    "    def __init__(self, w0, w1):\n",
    "        self.w0 = w0\n",
    "        self.w1 = w1\n",
    "\n",
    "    def convert(self, celsius):\n",
    "        return self.w1 * celsius + self.w0\n",
    "\n",
    "model = LinearModel.remote(w1=9/5, w0=32)\n",
    "ray.get(model.convert.remote(100))\n",
    "```\n",
    "\n",
    "</details>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642e3863",
   "metadata": {},
   "source": [
    "<!-- TODO: add Patterns/antipatterns based on above learnings-->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
